{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"* cudf: GPU DataFrame library for loading, joining, aggregating, filtering, and otherwise manipulating data\n* cupy: NumPy/SciPy-compatible array library for GPU-accelerated computing with Python","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\n\nimport pandas as pd\nimport numpy as np\nimport cupy\nimport cudf\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import KFold\nimport xgboost as xgb","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:29:18.533328Z","iopub.execute_input":"2022-08-24T04:29:18.533886Z","iopub.status.idle":"2022-08-24T04:29:20.630662Z","shell.execute_reply.started":"2022-08-24T04:29:18.533732Z","shell.execute_reply":"2022-08-24T04:29:20.629433Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"SEED = 42\nNAN_VALUE = -127    # will fit in int8\nFOLDS = 5\n\nTRAIN_PATH = '../input/amex-data-integer-dtypes-parquet-format/train.parquet'\nTEST_PATH = '../input/amex-data-integer-dtypes-parquet-format/test.parquet'","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:29:20.635291Z","iopub.execute_input":"2022-08-24T04:29:20.635836Z","iopub.status.idle":"2022-08-24T04:29:20.644305Z","shell.execute_reply.started":"2022-08-24T04:29:20.635796Z","shell.execute_reply":"2022-08-24T04:29:20.642219Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Process and Feature Engineer Train Data\n* customer_ID: [-16:]의 문자열을 16진수에서 10진수 정수로 변환\n* S_2: datetime으로 변환\n* 결측지 -127로 처리","metadata":{}},{"cell_type":"code","source":"def read_file(path='', usecols=None):\n    if usecols is not None:\n        df = cudf.read_parquet(path, columns=usecols)\n    else:\n        df = cudf.read_parquet(path)\n        \n    df['customer_ID'] = df['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n    df['S_2'] = cudf.to_datetime(df['S_2'])\n    df = df.fillna(NAN_VALUE)\n    print('shape of data:', df.shape)\n\n    return df\n\nprint('Reading train data...')\ntrain = read_file(path=TRAIN_PATH)","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:29:20.647714Z","iopub.execute_input":"2022-08-24T04:29:20.648478Z","iopub.status.idle":"2022-08-24T04:29:45.555328Z","shell.execute_reply.started":"2022-08-24T04:29:20.648438Z","shell.execute_reply":"2022-08-24T04:29:45.554218Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:29:45.558619Z","iopub.execute_input":"2022-08-24T04:29:45.559616Z","iopub.status.idle":"2022-08-24T04:29:45.803272Z","shell.execute_reply.started":"2022-08-24T04:29:45.559578Z","shell.execute_reply":"2022-08-24T04:29:45.802213Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### feature engineering\n* 연속형 변수\n    * customer_ID당 mean, std, min, max, last\n* 범주형 변수\n    * customer_ID당 count, last, nunique","metadata":{}},{"cell_type":"code","source":"def process_and_feature_engineer(df):\n    all_cols = [c for c in list(df.columns) if c not in ['customer_ID', 'S_2']]\n    cat_features = [\n        \"B_30\", \"B_38\", \"D_114\", \"D_116\", \"D_117\", \"D_120\", \"D_126\", \"D_63\",\n        \"D_64\",\"D_66\", \"D_68\"\n    ]\n    num_features = [col for col in all_cols if col not in cat_features]\n\n    # \n    df_num_agg = df.groupby('customer_ID')[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n    df_num_agg.columns = ['_'.join(x) for x in df_num_agg.columns]\n\n    df_cat_agg = df.groupby('customer_ID')[cat_features].agg(['count', 'last', 'nunique'])\n    df_cat_agg.columns = ['_'.join(x) for x in df_cat_agg.columns]\n\n    df = cudf.concat([df_num_agg, df_cat_agg], axis=1)\n    del df_num_agg, df_cat_agg\n    gc.collect()\n    print('shape after engineering', df.shape)\n\n    return df\n\ntrain = process_and_feature_engineer(train)","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:29:45.804983Z","iopub.execute_input":"2022-08-24T04:29:45.805356Z","iopub.status.idle":"2022-08-24T04:29:47.156213Z","shell.execute_reply.started":"2022-08-24T04:29:45.805320Z","shell.execute_reply":"2022-08-24T04:29:47.155076Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"* train_labels의 customer_ID도 똑같이 [-16:]의 문자열을 16진수에서 10진수 정수로 변환\n* train과 train_labels를 merge\n    * how='left'\n* target int8 로 변환","metadata":{}},{"cell_type":"code","source":"targets = cudf.read_csv('../input/amex-default-prediction/train_labels.csv')\ntargets['customer_ID'] = targets['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\ntargets = targets.set_index('customer_ID')\ntrain = train.merge(targets, left_index=True, right_index=True, how='left')\ntrain['target'] = train['target'].astype('int8')\ndel targets\ngc.collect()\n\ntrain = train.sort_index().reset_index()\nFEATURES = train.columns[1:-1]\nprint(f'There are {len(FEATURES)} features!')","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:29:47.157733Z","iopub.execute_input":"2022-08-24T04:29:47.158089Z","iopub.status.idle":"2022-08-24T04:29:48.808536Z","shell.execute_reply.started":"2022-08-24T04:29:47.158055Z","shell.execute_reply":"2022-08-24T04:29:48.807243Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### XGB hyperparameters\n* subsample: 학습 데이터 사용 비율 -> 과적합 방지할 수 있다.\n* colsample_bytree: column 사용 비율","metadata":{}},{"cell_type":"code","source":"xgb_parms = { \n    'max_depth': 4, \n    'learning_rate': 0.05, \n    'subsample': 0.8,\n    'colsample_bytree': 0.6, \n    'eval_metric': 'logloss',\n    'objective': 'binary:logistic',\n    'tree_method': 'gpu_hist',\n    'predictor': 'gpu_predictor',\n    'random_state': SEED\n}","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:29:48.813131Z","iopub.execute_input":"2022-08-24T04:29:48.813586Z","iopub.status.idle":"2022-08-24T04:29:48.822150Z","shell.execute_reply.started":"2022-08-24T04:29:48.813551Z","shell.execute_reply":"2022-08-24T04:29:48.820571Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class IterLoadForDMatrix(xgb.core.DataIter):\n    def __init__(self, df=None, features=None, target=None, batch_size=256 * 1024):\n        self.features = features\n        self.target = target\n        self.df = df\n        self.it = 0\n        self.batch_size = batch_size\n        self.batches = int(np.ceil(len(df) / self.batch_size))\n        super().__init__()\n\n    def reset(self):\n        self.it = 0\n\n    def next(self, input_data):\n        if self.it == self.batches:\n            return 0\n\n        a = self.it * self.batch_size\n        b = min((self.it + 1) * self.batch_size, len(self.df))\n        dt = cudf.DataFrame(self.df.iloc[a:b])\n        input_data(data=dt[self.features], label=dt[self.target])\n        self.it += 1\n        return 1","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:29:48.824106Z","iopub.execute_input":"2022-08-24T04:29:48.824519Z","iopub.status.idle":"2022-08-24T04:29:48.837232Z","shell.execute_reply.started":"2022-08-24T04:29:48.824484Z","shell.execute_reply":"2022-08-24T04:29:48.836208Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### 평가 지표","metadata":{}},{"cell_type":"code","source":"def amex_metric_mod(y_true, y_pred):\n    labels = np.transpose(np.array([y_true, y_pred]))\n    labels = labels[labels[:, 1].argsort()[::-1]]\n    weights = np.where(labels[:, 0] == 0, 20, 1)\n    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n    top_four = np.sum(cut_vals[:, 0]) / np.sum(labels[:, 0])\n\n    gini = [0, 0]\n    for i in [1, 0]:\n        labels = np.transpose(np.array([y_true, y_pred]))\n        labels = labels[labels[:, i].argsort()[::-1]]\n        weight = np.where(labels[:, 0] == 0, 20, 1)\n        weight_random = np.cumsum(weight / np.sum(weight))\n        total_pos = np.sum(labels[:, 0] *  weight)\n        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n        lorentz = cum_pos_found / total_pos\n        gini[i] = np.sum((lorentz - weight_random) * weight)\n\n    return 0.5 * (gini[1] / gini[0] + top_four)","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:29:48.840362Z","iopub.execute_input":"2022-08-24T04:29:48.841984Z","iopub.status.idle":"2022-08-24T04:29:48.856959Z","shell.execute_reply.started":"2022-08-24T04:29:48.841948Z","shell.execute_reply":"2022-08-24T04:29:48.855879Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### xgboost 학습\n* DeviceQuantileDMatrix - GPU로 학습할 때 사용\n* DMatrix - XGBoost에서 사용하는 data structure. 메모리 효율과 학습 속도에 최적화 되어 있다.","metadata":{}},{"cell_type":"code","source":"importances = []\noof = []\ntrain = train.to_pandas()\nTRAIN_SUBSAMPLE = 1.0\ngc.collect()\n\nskf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(train, train.target)):\n    # Train with subsample of train fold data\n    if TRAIN_SUBSAMPLE < 1.0:\n        np.random.seed(SEED)\n        train_idx = np.random.choice(train_idx, int(len(train_idx) * TRAIN_SUBSAMPLE), replace=False)\n        np.random.seed(None)\n\n    print('#' * 25)\n    print('### Fold', fold + 1)\n    print('### Train size', len(train_idx), 'Valid size', len(valid_idx))\n    print(f'### Training with {int(TRAIN_SUBSAMPLE * 100)} % fold data...')\n    print('#' * 25)\n\n    # train, valid, test for fold k\n    Xy_train = IterLoadForDMatrix(train.loc[train_idx], FEATURES, 'target')\n    X_valid = train.loc[valid_idx, FEATURES]\n    y_valid = train.loc[valid_idx, 'target']\n\n    dtrain = xgb.DeviceQuantileDMatrix(Xy_train, max_bin=256)\n    dvalid = xgb.DMatrix(data=X_valid, label=y_valid)\n\n    # train model fold k\n    model = xgb.train(\n        xgb_parms,\n        dtrain=dtrain,\n        evals=[(dtrain, 'train'), (dvalid, 'valid')],\n        num_boost_round=9999,\n        early_stopping_rounds=100,\n        verbose_eval=100\n    )\n    model.save_model(f'XGB_fold{fold}.xgb')\n\n    # get feature importance for fold k\n    dd = model.get_score(importance_type='weight')\n    df = pd.DataFrame({'feature': dd.keys(), f'importance_{fold}': dd.values()})\n    importances.append(df)\n\n    # infer oof fold k\n    oof_preds = model.predict(dvalid)\n    acc = amex_metric_mod(y_valid.values, oof_preds)\n    print('Kaggle Metric = ', acc, '\\n')\n\n    # save oof\n    df = train.loc[valid_idx, ['customer_ID', 'target']].copy()\n    df['oof_pred'] = oof_preds\n    oof.append(df)\n\n    del dtrain, Xy_train, dd, df\n    del X_valid, y_valid, dvalid, model\n    gc.collect()\n\nprint('#' * 25)\noof = pd.concat(oof, axis=0, ignore_index=True).set_index('customer_ID')\nacc = amex_metric_mod(oof.target.values, oof.oof_pred.values)\nprint('OVERALL CV Kaggle Metric = ', acc)\n\nwith open('score_xgboost.txt', 'w') as f:\n    f.write(str(acc))","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:29:48.858522Z","iopub.execute_input":"2022-08-24T04:29:48.858878Z","iopub.status.idle":"2022-08-24T04:38:50.933060Z","shell.execute_reply.started":"2022-08-24T04:29:48.858845Z","shell.execute_reply":"2022-08-24T04:38:50.931921Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"del train\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:38:50.934772Z","iopub.execute_input":"2022-08-24T04:38:50.935157Z","iopub.status.idle":"2022-08-24T04:38:51.072739Z","shell.execute_reply.started":"2022-08-24T04:38:50.935119Z","shell.execute_reply":"2022-08-24T04:38:51.071156Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"##### Save OOF Preds","metadata":{}},{"cell_type":"code","source":"oof_xgb = pd.read_parquet(TRAIN_PATH, columns=['customer_ID']).drop_duplicates()\noof_xgb['customer_ID_hash'] = oof_xgb['customer_ID'].apply(lambda x: int(x[-16:], 16)).astype('int64')\noof_xgb = oof_xgb.set_index('customer_ID_hash')\noof_xgb = oof_xgb.merge(oof, left_index=True, right_index=True)\noof_xgb = oof_xgb.sort_index().reset_index(drop=True)\noof_xgb.to_csv(f'oof_xgb.csv', index=False)\noof_xgb.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:38:51.074474Z","iopub.execute_input":"2022-08-24T04:38:51.075206Z","iopub.status.idle":"2022-08-24T04:38:54.885326Z","shell.execute_reply.started":"2022-08-24T04:38:51.075149Z","shell.execute_reply":"2022-08-24T04:38:54.884116Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"plt.hist(oof_xgb.oof_pred.values, bins=100)\nplt.title('OOF Predictions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:38:54.889671Z","iopub.execute_input":"2022-08-24T04:38:54.889989Z","iopub.status.idle":"2022-08-24T04:38:55.247980Z","shell.execute_reply.started":"2022-08-24T04:38:54.889961Z","shell.execute_reply":"2022-08-24T04:38:55.247086Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"del oof_xgb, oof\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:38:55.249394Z","iopub.execute_input":"2022-08-24T04:38:55.250106Z","iopub.status.idle":"2022-08-24T04:38:55.383786Z","shell.execute_reply.started":"2022-08-24T04:38:55.250064Z","shell.execute_reply":"2022-08-24T04:38:55.382806Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"##### Feature Importance","metadata":{}},{"cell_type":"code","source":"df = importances[0].copy()\nfor k in range(1, FOLDS):\n    df = df.merge(importances[k], on='feature', how='left')\n    df['importance'] = df.iloc[:, 1:].mean(axis=1)\n    df = df.sort_values('importance', ascending=False)\n    df.to_csv(f'xgb_feature_importance.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:38:55.385417Z","iopub.execute_input":"2022-08-24T04:38:55.386010Z","iopub.status.idle":"2022-08-24T04:38:55.429427Z","shell.execute_reply.started":"2022-08-24T04:38:55.385975Z","shell.execute_reply":"2022-08-24T04:38:55.428574Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"NUM_FEATURES = 20\nplt.figure(figsize=(10, 5 * NUM_FEATURES // 10))\nplt.barh(np.arange(NUM_FEATURES, 0, -1), df.importance.values[:NUM_FEATURES])\nplt.yticks(np.arange(NUM_FEATURES, 0, -1), df.feature.values[:NUM_FEATURES])\nplt.title(f'XGB Feature Importance - Top {NUM_FEATURES}')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:38:55.430864Z","iopub.execute_input":"2022-08-24T04:38:55.431239Z","iopub.status.idle":"2022-08-24T04:38:55.716056Z","shell.execute_reply.started":"2022-08-24T04:38:55.431205Z","shell.execute_reply":"2022-08-24T04:38:55.715092Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Process and Feature Engineer Test data\n* test data split to 4 parts","metadata":{}},{"cell_type":"code","source":"def get_rows(customers, test, NUM_PARTS=4, verbose=''):\n    chunk = len(customers) // NUM_PARTS\n    if verbose != '':\n        print(f'We will process {verbose} data as {NUM_PARTS} separate parts.')\n        print(f'There will be {chunk} customers in each part (except the last part).')\n        print('Below are number of rows in each part:')\n    rows = []\n\n    for k in range(NUM_PARTS):\n        if k == NUM_PARTS - 1:\n            cc = customers[k * chunk:]\n        else:\n            cc = customers[k * chunk:(k + 1) * chunk]\n        s = test.loc[test.customer_ID.isin(cc)].shape[0]\n        rows.append(s)\n    if verbose != '':\n        print(rows)\n    return rows, chunk\n\nNUM_PARTS = 4\n\nprint(f'Reading test data...')\ntest = read_file(path=TEST_PATH, usecols=['customer_ID', 'S_2'])\ncustomers = test[['customer_ID']].drop_duplicates().sort_index().values.flatten()\nrows, num_cust = get_rows(customers, test[['customer_ID']], NUM_PARTS=NUM_PARTS, verbose='test')","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:38:55.717534Z","iopub.execute_input":"2022-08-24T04:38:55.718020Z","iopub.status.idle":"2022-08-24T04:38:58.818236Z","shell.execute_reply.started":"2022-08-24T04:38:55.717983Z","shell.execute_reply":"2022-08-24T04:38:58.817240Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"##### Infer Test","metadata":{}},{"cell_type":"code","source":"skip_rows = 0\nskip_cust = 0\ntest_preds = []\n\nfor k in range(NUM_PARTS):\n    # read part of test data\n    print(f'\\nReading test data...')\n    test = read_file(path=TEST_PATH)\n    test = test.iloc[skip_rows:skip_rows + rows[k]]\n    skip_rows += rows[k]\n    print(f'=> Test part {k + 1} has shape', test.shape)\n    \n    # process and feature engineer part of test data\n    test = process_and_feature_engineer(test)\n    if k == NUM_PARTS - 1:\n        test = test.loc[customers[skip_cust:]]\n    else:\n        test = test.loc[customers[skip_cust:skip_cust + num_cust]]\n    skip_cust += num_cust\n\n    # test data for xgb\n    X_test = test[FEATURES]\n    dtest = xgb.DMatrix(data=X_test)\n    test = test[['P_2_mean']]   # reduce memory\n    del X_test\n    gc.collect()\n\n    # infer xgb models on test data\n    model = xgb.Booster()\n    model.load_model(f'XGB_fold0.xgb')\n    preds = model.predict(dtest)\n    for f in range(1, FOLDS):\n        model.load_model(f'XGB_fold{f}.xgb')\n        preds += model.predict(dtest)\n    preds /= FOLDS\n    test_preds.append(preds)\n\n    del dtest, model\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:38:58.819691Z","iopub.execute_input":"2022-08-24T04:38:58.820436Z","iopub.status.idle":"2022-08-24T04:41:36.391499Z","shell.execute_reply.started":"2022-08-24T04:38:58.820394Z","shell.execute_reply":"2022-08-24T04:41:36.390524Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"##### Create Submission CSV","metadata":{}},{"cell_type":"code","source":"test_preds = np.concatenate(test_preds)\ntest = cudf.DataFrame(index=customers, data={'prediction': test_preds})\nsub = cudf.read_csv('../input/amex-default-prediction/sample_submission.csv')[['customer_ID']]\nsub['customer_ID_hash'] = sub['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\nsub = sub.set_index('customer_ID_hash')\nsub = sub.merge(test[['prediction']], left_index=True, right_index=True, how='left')\nsub = sub.reset_index(drop=True)\n\n# display predictions\nsub.to_csv('submission_xgboost.csv', index=False)\nsub.to_csv('submission.csv', index=False)\nprint('Submission file shape is', sub.shape)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T04:41:36.393277Z","iopub.execute_input":"2022-08-24T04:41:36.393624Z","iopub.status.idle":"2022-08-24T04:41:37.593730Z","shell.execute_reply.started":"2022-08-24T04:41:36.393590Z","shell.execute_reply":"2022-08-24T04:41:37.592641Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}