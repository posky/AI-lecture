{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import early_stopping\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    'P_2', 'B_1', 'B_2', 'R_1', 'S_3', 'B_3', 'D_44', 'B_4', 'D_45', 'B_5',\n",
    "    'D_47', 'D_48', 'B_6', 'B_7', 'B_8', 'B_9', 'D_52', 'P_3', 'B_11', 'S_7',\n",
    "    'D_55', 'D_61', 'B_18', 'B_23', 'D_75', 'B_33', 'S_23', 'S_25', 'B_37',\n",
    "    'R_27', 'B_40', 'c_PD_239', 'c_PB_29', 'c_PR_21', 'c_BBBB2', 'c_RRR0',\n",
    "    'c_PD_348', 'c_PB_49', 'c_PR_41'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_process(df, label=None, test=False):\n",
    "    global FEATURES\n",
    "    def feature_select(df):\n",
    "        X = df.drop(['customer_ID', 'S_2', 'target'], axis=1).fillna(-127)\n",
    "        y = df['target']\n",
    "        select = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1, verbose=1), threshold='1.2*mean')\n",
    "        select.fit(X, y)\n",
    "        #   \n",
    "        # features = select.get_feature_names_out()\n",
    "        FEATURES = list(X.columns[select.get_support()])\n",
    "        \n",
    "        print(FEATURES)\n",
    "        df = df[FEATURES + ['target']]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def polynomial_feature(df):\n",
    "        categorical_features = [\n",
    "            'B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120',\n",
    "            'D_126', 'D_63', 'D_64', 'D_66', 'D_68'\n",
    "        ]\n",
    "        num_features = []\n",
    "        for col in [c for c in df.columns if c not in ['customer_ID', 'S_2', 'target']]:\n",
    "            if col not in categorical_features:\n",
    "                num_features.append(col)\n",
    "                \n",
    "        poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "        df_poly = poly.fit_transform(df[num_features].fillna(-127))\n",
    "        df[poly.get_feature_names(None)] = df_poly\n",
    "        \n",
    "        del df_poly\n",
    "        return df\n",
    "        \n",
    "\n",
    "    \n",
    "    print('groupby customer_ID tail(1)')\n",
    "    df = df.groupby('customer_ID').tail(1).set_index('customer_ID')\n",
    "    print('shape:', df.shape)\n",
    "\n",
    "    if not test:\n",
    "        print('dropna nan >= 80%')\n",
    "        df = df.dropna(axis=1, thresh=int(0.8 * len(df)))\n",
    "        print('shape:', df.shape)\n",
    "\n",
    "    print('add features')\n",
    "    df[\"c_PD_239\"] = df[\"D_39\"] / (df[\"P_2\"] * (-1) + 0.0001)\n",
    "    df[\"c_PB_29\"] = df[\"P_2\"] * (-1) / (df[\"B_9\"] * (1) + 0.0001)\n",
    "    df[\"c_PR_21\"] = df[\"P_2\"] * (-1) / (df[\"R_1\"] + 0.0001)\n",
    "\n",
    "    df[\"c_BBBB\"] = (df[\"B_9\"] + 0.001) / (df[\"B_23\"] + df[\"B_3\"] + 0.0001)\n",
    "    df[\"c_BBBB1\"] = (df[\"B_33\"] * (-1)) + (df[\"B_18\"] * (-1) + df[\"S_25\"] * (1) + 0.0001)\n",
    "    df[\"c_BBBB2\"] = (df[\"B_19\"] + df[\"B_20\"] + df[\"B_4\"] + 0.0001)\n",
    "\n",
    "    df[\"c_RRR0\"] = (df[\"R_3\"] + 0.001) / (df[\"R_2\"] + df[\"R_4\"] + 0.0001)\n",
    "    df[\"c_RRR1\"] = (df[\"D_62\"] + 0.001) / (df[\"D_112\"] + df[\"R_27\"] + 0.0001)\n",
    "\n",
    "    df[\"c_PD_348\"] = df[\"D_48\"] / (df[\"P_3\"] + 0.0001)\n",
    "    df[\"c_PD_355\"] = df[\"D_55\"] / (df[\"P_3\"] + 0.0001)\n",
    "\n",
    "    df[\"c_PD_439\"] = df[\"D_39\"] / (df[\"P_4\"] + 0.0001)\n",
    "    df[\"c_PB_49\"] = df[\"B_9\"] / (df[\"P_4\"] + 0.0001)\n",
    "    df[\"c_PR_41\"] = df[\"R_1\"] / (df[\"P_4\"] + 0.0001)\n",
    "    print('shape:', df.shape)\n",
    "    \n",
    "    if label is not None:\n",
    "        print('merge with label')\n",
    "        df = df.merge(label, how='left', on='customer_ID')\n",
    "        del label\n",
    "        print('shape:', df.shape)\n",
    "    \n",
    "    print('feature select')\n",
    "    if not test:\n",
    "        # df = feature_select(df)\n",
    "        df = df[FEATURES + ['target']]\n",
    "    else:\n",
    "        df = df[FEATURES]\n",
    "    print('shape:', df.shape)\n",
    "    \n",
    "    print('polynomial features')\n",
    "    df = polynomial_feature(df)\n",
    "    print('shape:', df.shape)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groupby customer_ID tail(1)\n",
      "shape: (458913, 189)\n",
      "dropna nan >= 80%\n",
      "shape: (458913, 168)\n",
      "add features\n",
      "shape: (458913, 181)\n",
      "merge with label\n",
      "shape: (458913, 183)\n",
      "feature select\n",
      "shape: (458913, 40)\n",
      "polynomial features\n",
      "shape: (458913, 859)\n",
      "Wall time: 1min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_train = pd.read_parquet('./data/train.parquet')\n",
    "df_train_label = pd.read_csv('./data/train_labels.csv')\n",
    "df_train = features_process(df_train, label=df_train_label)\n",
    "\n",
    "del df_train_label\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>B_3</th>\n",
       "      <th>D_44</th>\n",
       "      <th>B_4</th>\n",
       "      <th>D_45</th>\n",
       "      <th>B_5</th>\n",
       "      <th>...</th>\n",
       "      <th>x35^2</th>\n",
       "      <th>x35 x36</th>\n",
       "      <th>x35 x37</th>\n",
       "      <th>x35 x38</th>\n",
       "      <th>x36^2</th>\n",
       "      <th>x36 x37</th>\n",
       "      <th>x36 x38</th>\n",
       "      <th>x37^2</th>\n",
       "      <th>x37 x38</th>\n",
       "      <th>x38^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.934745</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>1.007647</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.135021</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.740102</td>\n",
       "      <td>0.231717</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>3.056054e+00</td>\n",
       "      <td>9.534851e+02</td>\n",
       "      <td>6.103754e+02</td>\n",
       "      <td>0.093395</td>\n",
       "      <td>29.139024</td>\n",
       "      <td>18.653404</td>\n",
       "      <td>9.091339e+03</td>\n",
       "      <td>5819.838580</td>\n",
       "      <td>3725.581342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880519</td>\n",
       "      <td>0.034684</td>\n",
       "      <td>1.004028</td>\n",
       "      <td>0.006911</td>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.266275</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002001e+08</td>\n",
       "      <td>2.576277e+02</td>\n",
       "      <td>1.293924e+06</td>\n",
       "      <td>6.918065e+05</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>3.326849</td>\n",
       "      <td>1.778726</td>\n",
       "      <td>1.670895e+04</td>\n",
       "      <td>8933.571582</td>\n",
       "      <td>4776.405203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.880875</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.812649</td>\n",
       "      <td>0.006450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.251598</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.277662e+00</td>\n",
       "      <td>9.392085e+02</td>\n",
       "      <td>6.449954e+02</td>\n",
       "      <td>0.016324</td>\n",
       "      <td>11.999909</td>\n",
       "      <td>8.240861</td>\n",
       "      <td>8.821125e+03</td>\n",
       "      <td>6057.851511</td>\n",
       "      <td>4160.190949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.621776</td>\n",
       "      <td>0.012564</td>\n",
       "      <td>1.006183</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>0.287766</td>\n",
       "      <td>0.009937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.085103</td>\n",
       "      <td>0.118818</td>\n",
       "      <td>...</td>\n",
       "      <td>4.004001e+08</td>\n",
       "      <td>-2.541270e+06</td>\n",
       "      <td>4.107289e+06</td>\n",
       "      <td>1.566539e+06</td>\n",
       "      <td>16129.000000</td>\n",
       "      <td>-26068.253784</td>\n",
       "      <td>-9942.549126</td>\n",
       "      <td>4.213242e+04</td>\n",
       "      <td>16069.495559</td>\n",
       "      <td>6128.977811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.871900</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.815746</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.069952</td>\n",
       "      <td>0.004855</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>5.698698e+00</td>\n",
       "      <td>4.027262e+02</td>\n",
       "      <td>1.247313e+02</td>\n",
       "      <td>0.324752</td>\n",
       "      <td>22.950149</td>\n",
       "      <td>7.108059</td>\n",
       "      <td>1.621884e+03</td>\n",
       "      <td>502.325571</td>\n",
       "      <td>155.578930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458908</th>\n",
       "      <td>0.844229</td>\n",
       "      <td>0.028515</td>\n",
       "      <td>1.009866</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.128707</td>\n",
       "      <td>0.005893</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.073120</td>\n",
       "      <td>0.040532</td>\n",
       "      <td>...</td>\n",
       "      <td>4.901400e+09</td>\n",
       "      <td>7.728978e+03</td>\n",
       "      <td>1.191870e+08</td>\n",
       "      <td>1.349820e+06</td>\n",
       "      <td>0.012188</td>\n",
       "      <td>187.944949</td>\n",
       "      <td>2.128520</td>\n",
       "      <td>2.898260e+06</td>\n",
       "      <td>32823.464700</td>\n",
       "      <td>371.733357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458909</th>\n",
       "      <td>0.831279</td>\n",
       "      <td>0.292360</td>\n",
       "      <td>0.055656</td>\n",
       "      <td>0.006953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.233078</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.618023</td>\n",
       "      <td>0.018681</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002001e+08</td>\n",
       "      <td>3.048453e+03</td>\n",
       "      <td>1.433499e+07</td>\n",
       "      <td>6.960385e+05</td>\n",
       "      <td>0.092745</td>\n",
       "      <td>436.122880</td>\n",
       "      <td>21.176033</td>\n",
       "      <td>2.050817e+06</td>\n",
       "      <td>99577.827386</td>\n",
       "      <td>4835.021243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458910</th>\n",
       "      <td>0.800522</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>1.007023</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.066648</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.133731</td>\n",
       "      <td>0.019537</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.856966e+00</td>\n",
       "      <td>4.645642e+03</td>\n",
       "      <td>9.573463e+01</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>86.267975</td>\n",
       "      <td>1.777759</td>\n",
       "      <td>2.158199e+05</td>\n",
       "      <td>4447.488178</td>\n",
       "      <td>91.651202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458911</th>\n",
       "      <td>0.754129</td>\n",
       "      <td>0.015838</td>\n",
       "      <td>0.714486</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.408849</td>\n",
       "      <td>0.050048</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.070383</td>\n",
       "      <td>0.020531</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>7.178788e+00</td>\n",
       "      <td>1.649133e+03</td>\n",
       "      <td>9.926709e+01</td>\n",
       "      <td>0.515350</td>\n",
       "      <td>118.387732</td>\n",
       "      <td>7.126174</td>\n",
       "      <td>2.719638e+04</td>\n",
       "      <td>1637.045909</td>\n",
       "      <td>98.539555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458912</th>\n",
       "      <td>0.982175</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.992880</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.119165</td>\n",
       "      <td>0.014092</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750784</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>3.035270e-01</td>\n",
       "      <td>1.976261e+02</td>\n",
       "      <td>8.092972e+01</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.599848</td>\n",
       "      <td>0.245644</td>\n",
       "      <td>3.905606e+02</td>\n",
       "      <td>159.938210</td>\n",
       "      <td>65.496193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458913 rows × 859 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             P_2       B_1       B_2       R_1       S_3       B_3  D_44  B_4  \\\n",
       "0       0.934745  0.009382  1.007647  0.006104  0.135021  0.007174     0    5   \n",
       "1       0.880519  0.034684  1.004028  0.006911  0.165509  0.005068     0    1   \n",
       "2       0.880875  0.004284  0.812649  0.006450       NaN  0.007196     0    2   \n",
       "3       0.621776  0.012564  1.006183  0.007829  0.287766  0.009937     0    0   \n",
       "4       0.871900  0.007679  0.815746  0.001247       NaN  0.005528     0   21   \n",
       "...          ...       ...       ...       ...       ...       ...   ...  ...   \n",
       "458908  0.844229  0.028515  1.009866  0.001928  0.128707  0.005893     0    4   \n",
       "458909  0.831279  0.292360  0.055656  0.006953       NaN  0.233078     1   19   \n",
       "458910  0.800522  0.020563  1.007023  0.000957  0.066648  0.006314     0    6   \n",
       "458911  0.754129  0.015838  0.714486  0.000993  0.408849  0.050048     1   18   \n",
       "458912  0.982175  0.000077  0.992880  0.000809  0.119165  0.014092     0    1   \n",
       "\n",
       "            D_45       B_5  ...         x35^2       x35 x36       x35 x37  \\\n",
       "0       0.740102  0.231717  ...  1.000000e+02  3.056054e+00  9.534851e+02   \n",
       "1       0.266275  0.027000  ...  1.002001e+08  2.576277e+02  1.293924e+06   \n",
       "2       0.251598  0.001557  ...  1.000000e+02  1.277662e+00  9.392085e+02   \n",
       "3       0.085103  0.118818  ...  4.004001e+08 -2.541270e+06  4.107289e+06   \n",
       "4       0.069952  0.004855  ...  1.000000e+02  5.698698e+00  4.027262e+02   \n",
       "...          ...       ...  ...           ...           ...           ...   \n",
       "458908  0.073120  0.040532  ...  4.901400e+09  7.728978e+03  1.191870e+08   \n",
       "458909  0.618023  0.018681  ...  1.002001e+08  3.048453e+03  1.433499e+07   \n",
       "458910  0.133731  0.019537  ...  1.000000e+02  1.856966e+00  4.645642e+03   \n",
       "458911  0.070383  0.020531  ...  1.000000e+02  7.178788e+00  1.649133e+03   \n",
       "458912  0.750784  0.006617  ...  1.000000e+02  3.035270e-01  1.976261e+02   \n",
       "\n",
       "             x35 x38         x36^2       x36 x37      x36 x38         x37^2  \\\n",
       "0       6.103754e+02      0.093395     29.139024    18.653404  9.091339e+03   \n",
       "1       6.918065e+05      0.000662      3.326849     1.778726  1.670895e+04   \n",
       "2       6.449954e+02      0.016324     11.999909     8.240861  8.821125e+03   \n",
       "3       1.566539e+06  16129.000000 -26068.253784 -9942.549126  4.213242e+04   \n",
       "4       1.247313e+02      0.324752     22.950149     7.108059  1.621884e+03   \n",
       "...              ...           ...           ...          ...           ...   \n",
       "458908  1.349820e+06      0.012188    187.944949     2.128520  2.898260e+06   \n",
       "458909  6.960385e+05      0.092745    436.122880    21.176033  2.050817e+06   \n",
       "458910  9.573463e+01      0.034483     86.267975     1.777759  2.158199e+05   \n",
       "458911  9.926709e+01      0.515350    118.387732     7.126174  2.719638e+04   \n",
       "458912  8.092972e+01      0.000921      0.599848     0.245644  3.905606e+02   \n",
       "\n",
       "             x37 x38        x38^2  \n",
       "0        5819.838580  3725.581342  \n",
       "1        8933.571582  4776.405203  \n",
       "2        6057.851511  4160.190949  \n",
       "3       16069.495559  6128.977811  \n",
       "4         502.325571   155.578930  \n",
       "...              ...          ...  \n",
       "458908  32823.464700   371.733357  \n",
       "458909  99577.827386  4835.021243  \n",
       "458910   4447.488178    91.651202  \n",
       "458911   1637.045909    98.539555  \n",
       "458912    159.938210    65.496193  \n",
       "\n",
       "[458913 rows x 859 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 458913 entries, 0 to 458912\n",
      "Columns: 859 entries, P_2 to x38^2\n",
      "dtypes: float32(33), float64(821), int16(1), int64(1), int8(3)\n",
      "memory usage: 2.9 GB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [\n",
    "    'B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120',\n",
    "    'D_126', 'D_63', 'D_64', 'D_66', 'D_68'\n",
    "]\n",
    "\n",
    "cat_col = []\n",
    "categorical_cols_ = []\n",
    "n = 0\n",
    "for col in df_train.columns:\n",
    "    for coll in categorical_cols:\n",
    "        if col == coll:\n",
    "            cat_col.append(n)\n",
    "            categorical_cols_.append(col)\n",
    "            break\n",
    "    n += 1\n",
    "print(cat_col)\n",
    "print(categorical_cols_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/cdeotte/xgboost-starter-0-793/notebook\n",
    "# https://www.kaggle.com/kyakovlev\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/327534\n",
    "def amex_metric_mod(y_true, y_pred):\n",
    "    \n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1] / gini[0] + top_four), _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0\n",
      "y_train t=0 count: 272068\n",
      "y_train t=1 count: 95062\n",
      "y_val t=0 count: 68017\n",
      "y_val t=1 count: 23766\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.234048\tvalid_0's binary_logloss: 0.241011\n",
      "[200]\ttraining's binary_logloss: 0.224241\tvalid_0's binary_logloss: 0.237228\n",
      "[300]\ttraining's binary_logloss: 0.217793\tvalid_0's binary_logloss: 0.236783\n",
      "[400]\ttraining's binary_logloss: 0.212369\tvalid_0's binary_logloss: 0.236533\n",
      "[500]\ttraining's binary_logloss: 0.20724\tvalid_0's binary_logloss: 0.236447\n",
      "[600]\ttraining's binary_logloss: 0.202521\tvalid_0's binary_logloss: 0.23644\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's binary_logloss: 0.204953\tvalid_0's binary_logloss: 0.236404\n",
      "FOLD: 1\n",
      "y_train t=0 count: 272068\n",
      "y_train t=1 count: 95062\n",
      "y_val t=0 count: 68017\n",
      "y_val t=1 count: 23766\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.234124\tvalid_0's binary_logloss: 0.241183\n",
      "[200]\ttraining's binary_logloss: 0.224118\tvalid_0's binary_logloss: 0.23754\n",
      "[300]\ttraining's binary_logloss: 0.217774\tvalid_0's binary_logloss: 0.236923\n",
      "[400]\ttraining's binary_logloss: 0.21223\tvalid_0's binary_logloss: 0.236748\n",
      "[500]\ttraining's binary_logloss: 0.207135\tvalid_0's binary_logloss: 0.236753\n",
      "[600]\ttraining's binary_logloss: 0.202213\tvalid_0's binary_logloss: 0.236656\n",
      "[700]\ttraining's binary_logloss: 0.197745\tvalid_0's binary_logloss: 0.23659\n",
      "Early stopping, best iteration is:\n",
      "[682]\ttraining's binary_logloss: 0.19852\tvalid_0's binary_logloss: 0.236572\n",
      "FOLD: 2\n",
      "y_train t=0 count: 272068\n",
      "y_train t=1 count: 95062\n",
      "y_val t=0 count: 68017\n",
      "y_val t=1 count: 23766\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.234738\tvalid_0's binary_logloss: 0.238841\n",
      "[200]\ttraining's binary_logloss: 0.224744\tvalid_0's binary_logloss: 0.235099\n",
      "[300]\ttraining's binary_logloss: 0.218401\tvalid_0's binary_logloss: 0.234713\n",
      "[400]\ttraining's binary_logloss: 0.212928\tvalid_0's binary_logloss: 0.23452\n",
      "[500]\ttraining's binary_logloss: 0.207829\tvalid_0's binary_logloss: 0.234353\n",
      "[600]\ttraining's binary_logloss: 0.202965\tvalid_0's binary_logloss: 0.23426\n",
      "[700]\ttraining's binary_logloss: 0.19842\tvalid_0's binary_logloss: 0.234282\n",
      "Early stopping, best iteration is:\n",
      "[600]\ttraining's binary_logloss: 0.202965\tvalid_0's binary_logloss: 0.23426\n",
      "FOLD: 3\n",
      "y_train t=0 count: 272068\n",
      "y_train t=1 count: 95063\n",
      "y_val t=0 count: 68017\n",
      "y_val t=1 count: 23765\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.234644\tvalid_0's binary_logloss: 0.239563\n",
      "[200]\ttraining's binary_logloss: 0.224683\tvalid_0's binary_logloss: 0.235425\n",
      "[300]\ttraining's binary_logloss: 0.218393\tvalid_0's binary_logloss: 0.235003\n",
      "[400]\ttraining's binary_logloss: 0.2128\tvalid_0's binary_logloss: 0.234711\n",
      "[500]\ttraining's binary_logloss: 0.207619\tvalid_0's binary_logloss: 0.23449\n",
      "[600]\ttraining's binary_logloss: 0.202807\tvalid_0's binary_logloss: 0.234356\n",
      "[700]\ttraining's binary_logloss: 0.198337\tvalid_0's binary_logloss: 0.234324\n",
      "Early stopping, best iteration is:\n",
      "[686]\ttraining's binary_logloss: 0.198967\tvalid_0's binary_logloss: 0.234287\n",
      "FOLD: 4\n",
      "y_train t=0 count: 272068\n",
      "y_train t=1 count: 95063\n",
      "y_val t=0 count: 68017\n",
      "y_val t=1 count: 23765\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.23421\tvalid_0's binary_logloss: 0.240177\n",
      "[200]\ttraining's binary_logloss: 0.224243\tvalid_0's binary_logloss: 0.236465\n",
      "[300]\ttraining's binary_logloss: 0.217839\tvalid_0's binary_logloss: 0.235935\n",
      "[400]\ttraining's binary_logloss: 0.212348\tvalid_0's binary_logloss: 0.235769\n",
      "[500]\ttraining's binary_logloss: 0.207203\tvalid_0's binary_logloss: 0.235551\n",
      "[600]\ttraining's binary_logloss: 0.202532\tvalid_0's binary_logloss: 0.235513\n",
      "Early stopping, best iteration is:\n",
      "[563]\ttraining's binary_logloss: 0.204254\tvalid_0's binary_logloss: 0.235487\n",
      "score: 0.7661367102000136\n",
      "Wall time: 6min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {}\n",
    "feature_importances = []  # 특성 중요도 \n",
    "scores = []               # fold 별 점수 \n",
    "models = []               # 모델 \n",
    "pred_val = []\n",
    "yval = []\n",
    "\n",
    "X = df_train.drop(['target'], axis=1)\n",
    "y = df_train['target']\n",
    "\n",
    "# 교차 검증 클래스\n",
    "skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=2022)\n",
    "\n",
    "# 폴드별 데이터 나누기 \n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df_train[FEATURES], df_train[\"target\"])):\n",
    "    \n",
    "    print('FOLD:', fold)\n",
    "    \n",
    "    # 데이터 나누기\n",
    "    X_train = X.loc[train_idx].values\n",
    "    y_train = y.loc[train_idx].values\n",
    "    X_val = X.loc[val_idx].values\n",
    "    y_val = y.loc[val_idx].values\n",
    "\n",
    "    print(\"y_train t=0 count:\", len(y_train[y_train == 0]))\n",
    "    print(\"y_train t=1 count:\", len(y_train[y_train == 1]))\n",
    "    print(\"y_val t=0 count:\", len(y_val[y_val == 0]))\n",
    "    print(\"y_val t=1 count:\", len(y_val[y_val == 1]))\n",
    "\n",
    "\n",
    "    params = {\n",
    "        \"num_iterations\": 10000,\n",
    "        'learning_rate': 0.05,\n",
    "    }\n",
    "    \n",
    "    # LGBM 알고리즘\n",
    "    model = lgbm.LGBMClassifier(**params).fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val, y_val), (X_train, y_train)],\n",
    "        verbose=100,\n",
    "        callbacks=[early_stopping(100)],\n",
    "        categorical_feature=cat_col\n",
    "    )\n",
    "    \n",
    "    # 특성 중요도\n",
    "    feature_importances.append(model.feature_importances_)   \n",
    "    models.append(model)\n",
    "    pred_val = np.append(pred_val, model.predict_proba(X_val)[:, 1])\n",
    "    yval = np.append(yval, y_val)   \n",
    "    \n",
    "    del X_train, y_train, X_val, y_val, model\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "score = amex_metric_mod(yval, pred_val)[0]\n",
    "print('score:', score)\n",
    "with open('score_lightgbm_poly.txt', 'w') as f:\n",
    "    f.write(str(score))\n",
    "# f = open(\"lightgbm_score.txt\", \"a\")\n",
    "# f.write(str(score))\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_train, train_idx, val_idx, yval, pred_val, X, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_imp = pd.DataFrame(index=FEATURES)\n",
    "df_feat_imp[\"imp0\"] = feature_importances[0]\n",
    "df_feat_imp[\"imp1\"] = feature_importances[1]\n",
    "df_feat_imp[\"imp2\"] = feature_importances[2]\n",
    "df_feat_imp[\"imp3\"] = feature_importances[3]\n",
    "df_feat_imp[\"imp4\"] = feature_importances[4]\n",
    "df_feat_imp[\"mean_imp\"] = df_feat_imp.mean(axis=1).values\n",
    "\n",
    "df_feat_imp = df_feat_imp.sort_values(by=\"mean_imp\",ascending=False)\n",
    "\n",
    "df_feat_imp.to_csv(\"feat_imp_poly.csv\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "sns.barplot(x=df_feat_imp.index,y=df_feat_imp[\"mean_imp\"])\n",
    "plt.xticks([])\n",
    "print(df_feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groupby customer_ID tail(1)\n",
      "shape: (924621, 189)\n",
      "add features\n",
      "shape: (924621, 202)\n",
      "feature select\n",
      "shape: (924621, 39)\n",
      "polynomial features\n",
      "shape: (924621, 858)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_parquet('./data/test.parquet')\n",
    "\n",
    "df_test = features_process(df_test, test=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 924621 entries, 00000469ba478561f23a92a868bd366de6f6527a684c9a2e78fb826dcac3b9b7 to fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61cceb803ea8ec37634d\n",
      "Columns: 858 entries, P_2 to x38^2\n",
      "dtypes: float32(33), float64(821), int16(1), int8(3)\n",
      "memory usage: 5.8+ GB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction\n",
      "FOLD: 0\n",
      "FOLD: 1\n",
      "FOLD: 2\n",
      "FOLD: 3\n",
      "FOLD: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"prediction\")\n",
    "pred = []\n",
    "for fold in range(5):\n",
    "    print('FOLD:', fold)\n",
    "\n",
    "    if len(pred) == 0:\n",
    "        pred = models[fold].predict_proba(df_test)[:, 1]\n",
    "    else:\n",
    "        pred += models[fold].predict_proba(df_test)[:, 1]\n",
    "\n",
    "pred = pred / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.read_csv('./data/sample_submission.csv')\n",
    "subm[\"prediction\"] = pred\n",
    "subm.to_csv(\"submission_lightgbm_poly.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb22bed4442154fb3a19c63ce3e9993d02bf4fd0be5c23680b344f0e088c080f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
