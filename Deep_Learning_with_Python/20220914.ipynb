{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신 러닝의 네 가지 분류\n",
    "* 지도 학습(supervised learning): 훈련 데이터의 입력과 타깃 사이에 있는 관계를 학습하는 것.\n",
    "### 지도 학습\n",
    "* 시퀀스 생성(sequence generation): 사진이 주어지면 이를 설명하는 캡션을 생성. 시퀀스 생성은 이따금 일련의 분류 문체로 재구성할 수 있다.\n",
    "* 구문 트리(syntax tree) 예측: 문장이 주어지면 분히된 구문 트리를 예측한다.\n",
    "* 물체 감지(object detection): 사진이 주어지면 사진 안의 특정 물체 주위에 경계 상자(bounding box)를 그린다. 이는 분류 문제로 표현되거나, 경계 상자의 좌표를 벡터 회귀로 예측하는 회귀와 분류가 결합된 문제로 표현할 수 있다.\n",
    "* 이미지 분할(image segmentation): 사진이 주어젔을 때 픽셀 단위로 특정 물체에 마스킹(masking)을 한다.\n",
    "### 비지도 학습\n",
    "* 어떤 타깃도 사용하지 않고 입력 데이터에 대한 흥미로운 변환을 찾는다.\n",
    "* 데이터 시각화, 데이터 압축, 데이터ㅇ의 노이즈 제거 또는 데이터에 있는 상관관계를 더 잘 이해하기 위해 사용.\n",
    "* 비지도 학습(unsupervised learning)은 데이터 분석에서 빼놓을 수 없는 요소이며, 종종 지도 학습 문제를 풀기 전에 데이터셋을 잘 이해하기 위해 필수적으로 거치는 단계이다.\n",
    "* 차원 축소(dimensionality reduction)와 군집(clustering)이 비지도 학습에서 잘 알려진 범주이다.\n",
    "### 자기 지도 학습\n",
    "* 자기 지도 학습(self-supervised learning)은 지도 학습의 특별한 경우이지만 별도의 범주로 할 만큼 충분히 다르다.\n",
    "* 자기 지도 학습은 지도 학습이지만 사람이 만든 레이블을 사용하지 않는다.\n",
    "* 학습 과정에 사람이 개입하지 않는 지도 학습.\n",
    "* 레이블이 여전히 필요하지만 보통 경험적인 알고리즘(heuristic algorithm)을 사용해서 입력 데이터로부터 생성.\n",
    "* 오토인코더(autoencoder) 자기 지도 학습의 예.\n",
    "* 지난 프레임이 주어졌을 때 비디오의 다음 프레임을 예측하는 것이나, 이전 단어가 주어졌을 때 다음 단어를 예측하는 것이 자기 지도 학습의 예. (시간에 따른 지도 학습(temporally supervised learning))\n",
    "### 강화 학습 (reinforcement learning)\n",
    "* 강화 학습에서 에이전트(agent)는 환경에 대한 정보를 받아 보상을 최대화하는 행동을 선택하도록 학습된다.\n",
    "* 예를 들어 강화 학습으로 훈련된 신경망은 비디오 게임 화면을 입력으로 받고 게임 점수를 최대화하기 위한 게임 내의 행동들 출력할 수 있다.\n",
    "===\n",
    "* 분류와 회귀에서 사용하는 용어\n",
    "    * 샘플 또는 입력: 모델에 주입될 하나의 데이터 포인트\n",
    "    * 예측 또는 출력: 모델로부터 나오는 값\n",
    "    * 타깃: 정답. 외부 데이터 소스에 근거하여 모델이 완벽하게 예측해야 하는 값.\n",
    "    * 예측 오차 또는 손실 값: 모델의 예측과 타깃 사이의 거리를 측정한 값\n",
    "    * 클래스: 볘류 문제에서 선택할 수 있는 가능한 레이블의 집합.\n",
    "    * 레이블: 분류 문제에서 틀래스 할당의 구체적인 사례.\n",
    "    * 잠 값(ground-truth) 또는 꼬리표(annotation): 데이터셋에 대한 모든 타깃.\n",
    "    * 이진 분류: 각 입력 샘플이 2개의 배타적인 범주로 구분되는 분류 작업\n",
    "    * 다중 분류: 각 입력 샘플이 2개 이상의 범주로 구분되는 분류 작업.\n",
    "    * 다중 레이블 분류: 각 입력 샘플이 여러 개의 레이블에 할딩될 수 있는 분류 작업.\n",
    "    * 스칼라 회귀: 타깃이 연속적인 스칼라 값인 작업.\n",
    "    * 벡터 회귀: 타깃이 연속적인 값의 집합인 작업.\n",
    "    * 미니 배치 또는 배치: 모델에 의해 동시에 처리되는 소량의 샘플 묶음(일반적으로 8개에서 128개 사이). 샘플 개수는 GPU의 메모리 할당이 용이하도록 2의 거듭제곱으로 하는 경우가 많다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신 러닝 모델 평가\n",
    "* 몇 변의 에포크 후에 모델이 모두 과대적합되기 시작.\n",
    "* 머신 러닝의 목표는 처음 본 데이터에서 잘 작동하는 일반화된 모델을 얻는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련, 검증, 테스트 세트\n",
    "* 모델 평가의 핵심은 가용한 데이터를 항상 훈련, 검증, 테스트 3개의 세트로 나누는 것이다.\n",
    "* 훈련 세트에서 모델을 훈련하고 검증 세트에서 모델을 펑가한다.\n",
    "* 모델을 출시할 준비가 되면 테스트 세트에서 최종적으로 딱 한 번 모델을 테스트한다.\n",
    "* 모델을 개발할 때 항상 모델의 설정을 튜닝하기 때문이다.\n",
    "* 층의 수나 층의 유닛 수를 선택한다 (이런 파라미터를 네트워크의 가중치와 구분하기 의해 **하이퍼파라미터**(hyperparameter)라고 부른다.)\n",
    "* 검증 세트에서 모델의 성능을 평가하여 이련 튜닝을 수행한다.\n",
    "* 본질적으로 이련 튜닝도 어떤 파라미터 공간에서 줗은 설정을 찾는 학습이다.\n",
    "* 결국 검증 세트의 성능을 기반으로 모델의 설정을 튜닝하면 검증 세트로 모델을 직접 훈련하지 않더라도 빠르게 검증 세트에 과대적합될 수 있다.\n",
    "---\n",
    "* 이 현상의 핵심은 **정보 누설**(information leak) 개념에 있다.\n",
    "* 검증 세트의 모델 성능에 기반하여 모델의 하이퍼파라미터를 조정할 때마다 검증 데이터에 관한 정보가 모델로 새는 것이다.\n",
    "* 하나의 파라미터에 대해서 단 한 번만 튜닝한다면 아주 적은 정보가 누설된다.\n",
    "* 이런 검증 세트로는 모델을 평가할 만하다.\n",
    "* ㅎ지만 한 번 튜닝하고 나서 검증 세트에 펑가한 결과를 가지고 다시 모델을 조정하는 과정을 여러 번 반복하면, 검증 세트에 관한 정보를 모델에 아주 많이 노츨시키게 된다.\n",
    "---\n",
    "* 결국 검증 데이터에 맞추어 최적화했기 때문에 검증 데이터에 의도적으로 잘 수행되는 모델이 만들어진다.\n",
    "* 검증 데이터가 아니고 완전히 새도운 데이터에 대한 성능이 관샘 대상이라면 모델을 평가하기 위해 이전에 본 적 없는 완전히 다른 데이터셋을 사용해야 한다.\n",
    "* 모델은 간접적으로라도 테스트 세트에 대한 어떤 정보도 얻어서는 안 된다.\n",
    "* 테스트 세트 성능에 기초하여 튜닝한 모델의 모든 설정은 일칸화 성능을 왜곡시킬 것이다.\n",
    "---\n",
    "* 데이터를 훈련, 검증, 테스트 세트로 나누는 것은 간단해 보일 수 있지만 데이터가 적을 때는 몇 가지 고급 기법을 사용하면 도움이 된다.\n",
    "* 대표적인 세 가지 평가 방법인 단순 홀드아웃 검증(hold-out validation), K-겹 교차 검증(K-fold cross-validation), 려플링(shuffling)을 사용한 반복 K-겹 교차 검증(iterated K-fold cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단순 홀드아웃 검증\n",
    "* 데이터의 일정량을 테스트 세트로 떼어 놓는다.\n",
    "* 남은 데이터에서 훈련하고 테스트 세트로 평가."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "num_validation_samples = 10000\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_data = data[:num_validation_samples]\n",
    "data = data[num_validation_samples:]\n",
    "\n",
    "training_data = data[:]\n",
    "\n",
    "model = get_mode()\n",
    "model.train(training_data)\n",
    "validation_score = model.evaluate(validation_data)\n",
    "\n",
    "# model tuning\n",
    "# training, validation, ...\n",
    "\n",
    "model = get_model()\n",
    "model.train(np.concatenate([training_data, validation_data]))\n",
    "test_score = model.evaluate(test_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이 평가 방법은 단순해서 한 가지 단점이 있다.\n",
    "* 데이터가 적을 때는 검증 세트와 테스트 세트의 샘플이 너무 적어 주이전 전체 데이터를 통계적으로 대표하지 못할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-겹 교차 검증\n",
    "* 데이터를 동일한 크기를 가진 K개 분할로 나눈다.\n",
    "* 각 분할 i에 댑 남은 K - 1개의 분할로 ㅁ델을 훈련하고 분할 i에서 모델을 평가.\n",
    "* 최종 점수는 이렇게 얻은 K개의 점수를 평균한다.\n",
    "* 이 방벅은 모델의 성능이 데이터 분할에 따라 편차가 클 때 도움이 된다.\n",
    "* 홀드아웃 검증처럼 이 방법은 모델의 튜닝에 별개의 검층 세트를 사용하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "k = 4\n",
    "num_validation_samples = len(data) // k\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_scores = []\n",
    "for fold in range(k):\n",
    "    validation_data = data[num_validation_samples * fold: num_validation_samples * (fold + 1)]\n",
    "    training_data = data[:num_validation_samples * fold] + data[num_validation_samples * (fold + 1):]\n",
    "\n",
    "    model = get_model()\n",
    "    model.train(training_data)\n",
    "    validation_score = model.evaluate(validation_data)\n",
    "    validation_scores.append(validation_score)\n",
    "\n",
    "validation_score = np.average(validation_scores)\n",
    "\n",
    "model.get_model()\n",
    "model.train(data)\n",
    "test_score = model.evaluate(test_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 셔플링을 사용한 반복 K-겹 교차 검증\n",
    "* 이 방법은 비교적 가용 데이터가 적고 가능한 정확하게 모델을 평가하고자 할 때 사용한다.\n",
    "* 이 방법은 K-겹 교차 검증을 여러 번 적용하되 K개의 분할로 나누기 전에 매번 데이터를 무작의로 섞는다.\n",
    "* 최종 점수는 모든 K-겹 교차 검증을 실행해서 얻은 점수의 평균이 된다.\n",
    "* 결국 P * K개(P는 반복 횟수)의 모댜을 훈련하고 평가하므로 비용이 매우 많이 든다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기억해야 할 것\n",
    "* 대표성 있는 데이터: 훈련 세트와 테스트 세트가 주어진 데이터에 대한 대표성이 있어야 한다. 예를 들어 숫자 이미지를 분류하는 문제에서 샘플 배열이 클래스 순서대로 나열되어 있다고 가정한다. 이 배열의 처음 80%를 훈련 세트로 나머지 20%를 테스트 세트로 만들면 훈련 세트에는 0~7 숫자만 담겨 있고 테스트 세트에는 8~9 숫자만 담기게 된다. 훈련 세트와 테스트 세트로 나누기 전에 데이터를 무작의로 섞는 것이 일반적이다.\n",
    "* 시간의 방향: 과거로부터 미래를 예측하려고 한다면(예를 들어 내일의 날씨, 주식 시세 등) 데이터를 분할하기 전에 무작위로 섞어서는 절대 안 된다. 이렇게 하면 미래의 정보가 누설되기 때문이다. 즉 모델이 사실상 미래 데이터에서 훈련될 것이다. 이련 문제에서는 훈련 세트에 있는 데이터보다 테스트 세트에 있는 모든 데이터가 미래의 것이어야 한다.\n",
    "* 데이터 중복: 한 데이터셋에 어떤 데이터 포인트가 두 번 등장하면(실제 데이터셋에서 아주 흔한 일), 데이터를 섞고 훈련 세트와 검증 세트로 나누었을 때 훈련 세트와 검증 세트에 데이터 포인트가 중복될 수 있다. 이로 인해 훈련 데이터의 일부로 테스트하는 최악의 경우가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리, 특성 공학, 특성 학습\n",
    "* 많은 데이터 전처리와 특성 공학 기법은 특정 도메인에 종속적이다\n",
    "### 신경망을 위한 데이터 전처리\n",
    "* 데이터 전처리 목적은 주어진 원본 데이터를 신경망에 적용하기 쉽도록 만드는 것이다.\n",
    "* 벡터화(vectorization), 정규화(normalization), 누락된 값 다루기, 특성 추출 등이 포함.\n",
    "#### 벡터화\n",
    "* 신경망에서 모든 입력과 타깃은 부동 소수 데이터로 이루어진 텐서여야 한다.(또는 특정 경우에 정수로 이루어진 텐서)\n",
    "* 사운드, 이미지, 텍스트 등 처리해야 할 것이 무엇이든지 먼저 텐서로 변환해야 한다.\n",
    "* 이 단계를 **데이터 벡터화**(data vectorization).\n",
    "#### 값 정규화\n",
    "* 일반적으로 비교적 큰 값(예를 들어 네트워크의 가중치 초깃값보다 훨씬 큰 여러 자릿수를 가진 정수)이나 균일하지 않은 데이터(예를 들어 한 특성의 범위는 0~1이고 다른 특성은 100~200인 데이터)를 신경망에 주입하는 것인 위험하다.\n",
    "* 이렇게 하면 업데이트할 그래디언트가 커져 네트워크가 수렴하는 것을 방해한다.\n",
    "* 네트워크를 쉽게 학습시키려면 데이터가 다음 특징을 따라야 한다.\n",
    "    * 작은 값을 취한다. 일반적으로 대부분의 값이 0~1 사이여야 한다.\n",
    "    * 균일해야 한다. 즉 모든 특성이 대체로 비슷한 범위를 가져야 한다.\n",
    "* 추가적으로 다음에 나오는 엄격한 정규화 방법은 꼭 필수적이지는 않지만 자주 사용되고 도움이 될 수 있다.\n",
    "    * 각 특성별로 평균이 0이 되도록 정규화한다.\n",
    "    * 각 특성별로 표준 편차가 1이 되도록 정규화한다.\n",
    "    * `x -= x.mean(axis=0)`\n",
    "    * `x /= x.std(axis=0)`\n",
    "#### 누락된 값 다루기\n",
    "* 일반적으로 신경망에서 0이 사전에 정의된 의미 있는 아니라면 누락된 값을 0으로 입력해도 괜찮다.\n",
    "* 네트워크가 0이 누락된 데이터를 의미한다는 것을 학습하면 이 값을 무시하기 시작할 것이다.\n",
    "* 테스트 데이터에 누락된 값이 포함될 가능성이 있다고 가정.\n",
    "* 하지만 네트워크가 수락된 값이 없는 데이터에서 훈련되었다면 이 네크워크는 누락된 값을 무시하는 법을 알지 못한다.\n",
    "* 이런 경우에는 누락된 값이 있는 훈련 샘플을 고의적으로 만들어야 한다.\n",
    "* 훈련 샘플의 일부를 여러별 복사해서 테스트 데이터에서 빠질 것 같은 특성을 제거한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특성 공학\n",
    "* 특성 공학은 데이터와 머신 러닝 알고리즘에 관한 지식을 사용하는 단계이다.\n",
    "* 모델이 데이터를 주잇하기 전에 (학습이 아닌) 하드코딩된 변환을 적용하여 알고리즘이 더 잘 수행되도록 만들어 준다.\n",
    "* 많은 경우에 머신 러닝 모델이 임의의 데이터로부터 완벽한 학습을 한다고 개대하기는 어렵다.\n",
    "* 모델이 수월하게 작업할 수 있는 어떤 방식으로 데이터가 표현될 필요가 있다.\n",
    "---\n",
    "* 시계 이미지를 입력으로 받고 하루의 시간을 출력하는 모델을 개발한다고 가정.\n",
    "* 이미지의 원본 픽셀을 입력으로 사용한다면 어려운 머신 러닝 문체가 될 것이다.\n",
    "* 이를 해결하려면 합성곱 신경망이 필요할 것이고 이 네트워크를 훈련하기 위해 꽤 많은 컴퓨팅 자원도 필요하다.\n",
    "* 고수준에서 이 문체를 이해하고 있다면(우리는 시계에서 시간을 읽는 방법을 알고 있다.) 머신러닝 알고리즘을 위해 훨씬 더 좋은 입력 특성을 만들 수 있다.\n",
    "* 이를 들어 시계 바늘의 검은색 픽셀을 따라 각 바늘 끝의 (x, y) 좌표를 출력하는 간단한 파이썬 스크립트른 만든다.\n",
    "* 그다음 머신 러닝 알고리즘이 이 좌표와 적절한 시각을 연결하도록 쉽게 학습될 수 있다.\n",
    "---\n",
    "* 이보다 더 좋은 특성을 만들 수도 있다.\n",
    "* 촤표를 바꾸어 (x, y) 포인트를 이미지 중심에 대한 극좌표로 나타낼 수 있다.\n",
    "* 이제 각 시계 바늘의 각도가 입력된다.\n",
    "* 이렇게 특성을 준비하면 문제가 너무 쉬워져서 머신 러닝이 전혀 필요하지 않다.\n",
    "---\n",
    "* 특성을 더 간단한 방식으로 표현하여 문제를 쉽게 만든다.\n",
    "* 최근 딥러닝은 대부분 특성 공학이 필요하지 않다.\n",
    "* 신경망이 자동으로 원본 데이터에서 유용한 특성을 추출할 수 있다.\n",
    "* 좋은 특성은 적은 자원을 사용하여 문제를 더 멋지게 풀어낼 수 있다.\n",
    "* 좋은 특성은 더 적은 데이터로 문제를 풀 스 있다.\n",
    "* 딥러닝 모델이 스스로 특성을 학습하는 능력은 가용한 훈련 데이터가 많을 때 발휘된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
