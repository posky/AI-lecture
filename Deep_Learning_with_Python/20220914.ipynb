{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신 러닝의 네 가지 분류\n",
    "* 지도 학습(supervised learning): 훈련 데이터의 입력과 타깃 사이에 있는 관계를 학습하는 것.\n",
    "### 지도 학습\n",
    "* 시퀀스 생성(sequence generation): 사진이 주어지면 이를 설명하는 캡션을 생성. 시퀀스 생성은 이따금 일련의 분류 문체로 재구성할 수 있다.\n",
    "* 구문 트리(syntax tree) 예측: 문장이 주어지면 분히된 구문 트리를 예측한다.\n",
    "* 물체 감지(object detection): 사진이 주어지면 사진 안의 특정 물체 주위에 경계 상자(bounding box)를 그린다. 이는 분류 문제로 표현되거나, 경계 상자의 좌표를 벡터 회귀로 예측하는 회귀와 분류가 결합된 문제로 표현할 수 있다.\n",
    "* 이미지 분할(image segmentation): 사진이 주어젔을 때 픽셀 단위로 특정 물체에 마스킹(masking)을 한다.\n",
    "### 비지도 학습\n",
    "* 어떤 타깃도 사용하지 않고 입력 데이터에 대한 흥미로운 변환을 찾는다.\n",
    "* 데이터 시각화, 데이터 압축, 데이터ㅇ의 노이즈 제거 또는 데이터에 있는 상관관계를 더 잘 이해하기 위해 사용.\n",
    "* 비지도 학습(unsupervised learning)은 데이터 분석에서 빼놓을 수 없는 요소이며, 종종 지도 학습 문제를 풀기 전에 데이터셋을 잘 이해하기 위해 필수적으로 거치는 단계이다.\n",
    "* 차원 축소(dimensionality reduction)와 군집(clustering)이 비지도 학습에서 잘 알려진 범주이다.\n",
    "### 자기 지도 학습\n",
    "* 자기 지도 학습(self-supervised learning)은 지도 학습의 특별한 경우이지만 별도의 범주로 할 만큼 충분히 다르다.\n",
    "* 자기 지도 학습은 지도 학습이지만 사람이 만든 레이블을 사용하지 않는다.\n",
    "* 학습 과정에 사람이 개입하지 않는 지도 학습.\n",
    "* 레이블이 여전히 필요하지만 보통 경험적인 알고리즘(heuristic algorithm)을 사용해서 입력 데이터로부터 생성.\n",
    "* 오토인코더(autoencoder) 자기 지도 학습의 예.\n",
    "* 지난 프레임이 주어졌을 때 비디오의 다음 프레임을 예측하는 것이나, 이전 단어가 주어졌을 때 다음 단어를 예측하는 것이 자기 지도 학습의 예. (시간에 따른 지도 학습(temporally supervised learning))\n",
    "### 강화 학습 (reinforcement learning)\n",
    "* 강화 학습에서 에이전트(agent)는 환경에 대한 정보를 받아 보상을 최대화하는 행동을 선택하도록 학습된다.\n",
    "* 예를 들어 강화 학습으로 훈련된 신경망은 비디오 게임 화면을 입력으로 받고 게임 점수를 최대화하기 위한 게임 내의 행동들 출력할 수 있다.\n",
    "===\n",
    "* 분류와 회귀에서 사용하는 용어\n",
    "    * 샘플 또는 입력: 모델에 주입될 하나의 데이터 포인트\n",
    "    * 예측 또는 출력: 모델로부터 나오는 값\n",
    "    * 타깃: 정답. 외부 데이터 소스에 근거하여 모델이 완벽하게 예측해야 하는 값.\n",
    "    * 예측 오차 또는 손실 값: 모델의 예측과 타깃 사이의 거리를 측정한 값\n",
    "    * 클래스: 볘류 문제에서 선택할 수 있는 가능한 레이블의 집합.\n",
    "    * 레이블: 분류 문제에서 틀래스 할당의 구체적인 사례.\n",
    "    * 잠 값(ground-truth) 또는 꼬리표(annotation): 데이터셋에 대한 모든 타깃.\n",
    "    * 이진 분류: 각 입력 샘플이 2개의 배타적인 범주로 구분되는 분류 작업\n",
    "    * 다중 분류: 각 입력 샘플이 2개 이상의 범주로 구분되는 분류 작업.\n",
    "    * 다중 레이블 분류: 각 입력 샘플이 여러 개의 레이블에 할딩될 수 있는 분류 작업.\n",
    "    * 스칼라 회귀: 타깃이 연속적인 스칼라 값인 작업.\n",
    "    * 벡터 회귀: 타깃이 연속적인 값의 집합인 작업.\n",
    "    * 미니 배치 또는 배치: 모델에 의해 동시에 처리되는 소량의 샘플 묶음(일반적으로 8개에서 128개 사이). 샘플 개수는 GPU의 메모리 할당이 용이하도록 2의 거듭제곱으로 하는 경우가 많다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신 러닝 모델 평가\n",
    "* 몇 변의 에포크 후에 모델이 모두 과대적합되기 시작.\n",
    "* 머신 러닝의 목표는 처음 본 데이터에서 잘 작동하는 일반화된 모델을 얻는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련, 검증, 테스트 세트\n",
    "* 모델 평가의 핵심은 가용한 데이터를 항상 훈련, 검증, 테스트 3개의 세트로 나누는 것이다.\n",
    "* 훈련 세트에서 모델을 훈련하고 검증 세트에서 모델을 펑가한다.\n",
    "* 모델을 출시할 준비가 되면 테스트 세트에서 최종적으로 딱 한 번 모델을 테스트한다.\n",
    "* 모델을 개발할 때 항상 모델의 설정을 튜닝하기 때문이다.\n",
    "* 층의 수나 층의 유닛 수를 선택한다 (이런 파라미터를 네트워크의 가중치와 구분하기 의해 **하이퍼파라미터**(hyperparameter)라고 부른다.)\n",
    "* 검증 세트에서 모델의 성능을 평가하여 이련 튜닝을 수행한다.\n",
    "* 본질적으로 이련 튜닝도 어떤 파라미터 공간에서 줗은 설정을 찾는 학습이다.\n",
    "* 결국 검증 세트의 성능을 기반으로 모델의 설정을 튜닝하면 검증 세트로 모델을 직접 훈련하지 않더라도 빠르게 검증 세트에 과대적합될 수 있다.\n",
    "---\n",
    "* 이 현상의 핵심은 **정보 누설**(information leak) 개념에 있다.\n",
    "* 검증 세트의 모델 성능에 기반하여 모델의 하이퍼파라미터를 조정할 때마다 검증 데이터에 관한 정보가 모델로 새는 것이다.\n",
    "* 하나의 파라미터에 대해서 단 한 번만 튜닝한다면 아주 적은 정보가 누설된다.\n",
    "* 이런 검증 세트로는 모델을 평가할 만하다.\n",
    "* ㅎ지만 한 번 튜닝하고 나서 검증 세트에 펑가한 결과를 가지고 다시 모델을 조정하는 과정을 여러 번 반복하면, 검증 세트에 관한 정보를 모델에 아주 많이 노츨시키게 된다.\n",
    "---\n",
    "* 결국 검증 데이터에 맞추어 최적화했기 때문에 검증 데이터에 의도적으로 잘 수행되는 모델이 만들어진다.\n",
    "* 검증 데이터가 아니고 완전히 새도운 데이터에 대한 성능이 관샘 대상이라면 모델을 평가하기 위해 이전에 본 적 없는 완전히 다른 데이터셋을 사용해야 한다.\n",
    "* 모델은 간접적으로라도 테스트 세트에 대한 어떤 정보도 얻어서는 안 된다.\n",
    "* 테스트 세트 성능에 기초하여 튜닝한 모델의 모든 설정은 일칸화 성능을 왜곡시킬 것이다.\n",
    "---\n",
    "* 데이터를 훈련, 검증, 테스트 세트로 나누는 것은 간단해 보일 수 있지만 데이터가 적을 때는 몇 가지 고급 기법을 사용하면 도움이 된다.\n",
    "* 대표적인 세 가지 평가 방법인 단순 홀드아웃 검증(hold-out validation), K-겹 교차 검증(K-fold cross-validation), 려플링(shuffling)을 사용한 반복 K-겹 교차 검증(iterated K-fold cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단순 홀드아웃 검증\n",
    "* 데이터의 일정량을 테스트 세트로 떼어 놓는다.\n",
    "* 남은 데이터에서 훈련하고 테스트 세트로 평가."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "num_validation_samples = 10000\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_data = data[:num_validation_samples]\n",
    "data = data[num_validation_samples:]\n",
    "\n",
    "training_data = data[:]\n",
    "\n",
    "model = get_mode()\n",
    "model.train(training_data)\n",
    "validation_score = model.evaluate(validation_data)\n",
    "\n",
    "# model tuning\n",
    "# training, validation, ...\n",
    "\n",
    "model = get_model()\n",
    "model.train(np.concatenate([training_data, validation_data]))\n",
    "test_score = model.evaluate(test_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이 평가 방법은 단순해서 한 가지 단점이 있다.\n",
    "* 데이터가 적을 때는 검증 세트와 테스트 세트의 샘플이 너무 적어 주이전 전체 데이터를 통계적으로 대표하지 못할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-겹 교차 검증\n",
    "* 데이터를 동일한 크기를 가진 K개 분할로 나눈다.\n",
    "* 각 분할 i에 댑 남은 K - 1개의 분할로 ㅁ델을 훈련하고 분할 i에서 모델을 평가.\n",
    "* 최종 점수는 이렇게 얻은 K개의 점수를 평균한다.\n",
    "* 이 방벅은 모델의 성능이 데이터 분할에 따라 편차가 클 때 도움이 된다.\n",
    "* 홀드아웃 검증처럼 이 방법은 모델의 튜닝에 별개의 검층 세트를 사용하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "k = 4\n",
    "num_validation_samples = len(data) // k\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_scores = []\n",
    "for fold in range(k):\n",
    "    validation_data = data[num_validation_samples * fold: num_validation_samples * (fold + 1)]\n",
    "    training_data = data[:num_validation_samples * fold] + data[num_validation_samples * (fold + 1):]\n",
    "\n",
    "    model = get_model()\n",
    "    model.train(training_data)\n",
    "    validation_score = model.evaluate(validation_data)\n",
    "    validation_scores.append(validation_score)\n",
    "\n",
    "validation_score = np.average(validation_scores)\n",
    "\n",
    "model.get_model()\n",
    "model.train(data)\n",
    "test_score = model.evaluate(test_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 셔플링을 사용한 반복 K-겹 교차 검증\n",
    "* 이 방법은 비교적 가용 데이터가 적고 가능한 정확하게 모델을 평가하고자 할 때 사용한다.\n",
    "* 이 방법은 K-겹 교차 검증을 여러 번 적용하되 K개의 분할로 나누기 전에 매번 데이터를 무작의로 섞는다.\n",
    "* 최종 점수는 모든 K-겹 교차 검증을 실행해서 얻은 점수의 평균이 된다.\n",
    "* 결국 P * K개(P는 반복 횟수)의 모댜을 훈련하고 평가하므로 비용이 매우 많이 든다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기억해야 할 것\n",
    "* 대표성 있는 데이터: 훈련 세트와 테스트 세트가 주어진 데이터에 대한 대표성이 있어야 한다. 예를 들어 숫자 이미지를 분류하는 문제에서 샘플 배열이 클래스 순서대로 나열되어 있다고 가정한다. 이 배열의 처음 80%를 훈련 세트로 나머지 20%를 테스트 세트로 만들면 훈련 세트에는 0~7 숫자만 담겨 있고 테스트 세트에는 8~9 숫자만 담기게 된다. 훈련 세트와 테스트 세트로 나누기 전에 데이터를 무작의로 섞는 것이 일반적이다.\n",
    "* 시간의 방향: 과거로부터 미래를 예측하려고 한다면(예를 들어 내일의 날씨, 주식 시세 등) 데이터를 분할하기 전에 무작위로 섞어서는 절대 안 된다. 이렇게 하면 미래의 정보가 누설되기 때문이다. 즉 모델이 사실상 미래 데이터에서 훈련될 것이다. 이련 문제에서는 훈련 세트에 있는 데이터보다 테스트 세트에 있는 모든 데이터가 미래의 것이어야 한다.\n",
    "* 데이터 중복: 한 데이터셋에 어떤 데이터 포인트가 두 번 등장하면(실제 데이터셋에서 아주 흔한 일), 데이터를 섞고 훈련 세트와 검증 세트로 나누었을 때 훈련 세트와 검증 세트에 데이터 포인트가 중복될 수 있다. 이로 인해 훈련 데이터의 일부로 테스트하는 최악의 경우가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
