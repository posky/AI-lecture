{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과대적합과 과소적합\n",
    "* 머신 러닝의 근본적인 이슈는 촡적화와 일반화 사이의 줄다리기이다.\n",
    "* **최적화**(optimization)는 가능한 훈련 데이터에서 최고의 성능을 얻으려고 모델을 조정하는 과정이다.\n",
    "* **일반화**(generalization)는 훈련된 모델이 이전에 본 적 없는 데이터에서 얼마나 잘 수행되는지 의미한다.\n",
    "---\n",
    "* 훈련 초기에 최적화와 일반화는 상호 연관되어 있다.\n",
    "* 훈련 데이터의 손실이 낮아질수록 테스테 데이터의 손실도 낮아진다.\n",
    "* 이런 상황이 발행할 때 모델이 **과소적합**(underfitting)되었다고 한다.\n",
    "* 하지만 훈련 데이터에 여러 번 반복 학습하고 나면 어느 시점부터 일반화 성능이 더 이상 높아지지 않는다.\n",
    "* 검증 세트의 성능이 멈추고 감소되기 시작한다.\n",
    "* 즉 모델이 과대적합되기 시작한다.\n",
    "---\n",
    "* 모델이 관련성이 없고 좋지 못한 패턴을 훈련 데이터에서 학습하지 못하도록 하려면 **가장 좋은 방법은 더 많은 훈련 데이터를 모으는 것이다.**\n",
    "* 데이터를 더 모으는 것이 불가능할 때 차선책은 모델이 수용할 수 있는 정보의 양을 조절하거나 저장할 수 있는 정보에 제약을 가하는 것이다.\n",
    "---\n",
    "* 이런 식으로 과대적합을 피하는 처리 과정을 **규제**(regularization)라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네트워크 크기 축소\n",
    "* 과대적합을 막는 가장 단순한 방법은 모델의 크기, 즉 모델에 있는 학습 파라미터의 수를 줄이는 것이다.\n",
    "* 딥러닝에서 모델에 있는 학습 파라미터의 수를 종종 모델의 용량(capacity)라고 말한다.\n",
    "---\n",
    "* 다른 한편으로 네트읕크가 기억 용량에 제한이 있다면 이런 매핑을 쉽게 학습하지 못할 것이다.\n",
    "* 따라서 손실을 최소화하기 위해 타깃에 대한 예측 성능을 가진 압축된 표현을 학습해야 한다.\n",
    "* 정확히 이련 표현이 우리 관심 대상이다.\n",
    "* 동시에 기억해야 할 것은 과소적합되지 않도록 충분한 파라미터를 가진 모델을 사용해야 한다는 점이다.\n",
    "---\n",
    "* 데이터에 알맞은 모델 크기를 찾으려면 각기 다른 구조를 (당연히 테스트 세트가 아니고 검증 세트에서) 평가해 보아야 한다.\n",
    "* 적절한 모델 크기를 찾는 일반적ㅎ예 작업 흐름은 비교적 적은 수의 층과 파라미터로 시작한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(6, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(6, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 용량이 큰 네트워크는 훈련 손실이 매우 빠르게 0에 가까워진다.\n",
    "* 용량이 많은 네트워크일수록 더 빠르게 훈련 데이터를 모델링할 수 있다.(결국 훈련 손실아 낮아진다.)\n",
    "* 하지만 더욱 과대적합에 민감해진다.(결국 훈련과 검증 손실 사이에 큰 차이가 발생한다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가중치 규제 추가\n",
    "* **오캄의 면도날**(Occam's razor) 이론.\n",
    "* 어떤 것에 대한 두 가지의 설명이 있다면 더 적은 가정이 필요한 간단한 설명이 옳을 것이라는 이론.\n",
    "* 이 개념은 신경망으로 학습되는 모델에도 적용된다.\n",
    "* 어떤 훈련 데이터와 네트워크 구조가 주어졌을 때 데이터를 설명할 수 있는 가중치 값의 집합은 여러 개(여러 개의 모델)이다.\n",
    "* 간단한 모델이 복잡한 모델보다 덜 과대적합될 가능성이 높다.\n",
    "---\n",
    "* 여기에서 간단한 모델은 파라미터 값 분포의 엔트로피가 작은 모델이다.(또는 앞 절에서 본 것처럼 적은 수의 파라미터를 가진 모델이다)\n",
    "* 그러므로 과대적합을 완화하기 위한 일반적인 방법은 네트워크의 복잡도에 제한을 두어 가중치가 작은 값을 가지도록 강제하는 것이다.\n",
    "* 가중치 값의 분포가 더 균일하게 된다.\n",
    "* 이를 **가중치 규제**(weight regularization)라고 하며, 네트워크의 손실 함수에 큰 가중치에 연관된 비용을 추가한다.\n",
    "    * **L1 규제**: 가중치의 절댓값에 비례하는 비용이 추가된다.(가중치의 **L1 노름**(norm))\n",
    "    * **L2 규제**: 가중치의 제곱에 비례하는 비용이 추가된다.(가중치의 **L2 노름**). L2 규제는 신경망에서 **가중치 감쇠**(weight decay)라고도 부른다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `l2(0.001)`는 가중치 행렬의 모든 원소를 제곱하고 0.001을 곱하여 네트워크의 전체 손실에 더해진다는 의미이다.\n",
    "* 이 페널티(penalty) 항는 훈련할 때만 추가된다.\n",
    "* 이 네트워크의 손실은 테스트보다 훈련할 때 더 높을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from keras import regularizers\n",
    "\n",
    "regularizers.l1(0.001)\n",
    "\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 드롭아웃 추가\n",
    "* **드롭아웃**(dropout)은 토론토 대학의 제프리 힌튼과 그의 학생들이 개발했다.\n",
    "* 신경망을 위해 사용되는 규제 기법 중에서 가장 효과적이고 널리 사용되는 방법 중 하나이다.\n",
    "* 네트워크 층에 드롭아웃을 적용하면 훈련하는 동안 무작위로 층의 일부 출력 특성을 제외시킨다. (0으로 만든다.)\n",
    "* 한 층이 정상적으로 훈련하는 동안에는 어떤 입력 샘플에 대해 [0.2, 0.5, 1.3, 0.8, 1,1] 벡터를 출력한다고 가정한다.\n",
    "* 드롭아웃을 적용하면 이 벡터의 일부가 무작위로 0으로 바뀐다.\n",
    "* 예를 들어 [0, 0.5, 1.3, 0, 1.1]이 된다.\n",
    "* 드롭아웃 비율은 0이 될 특성의 비율이다.\n",
    "* 보통 0.2에서 0.5 사이로 지정된다.\n",
    "* 테스트 단계게서는 어떤 유닛도 드롭아얘되지 않는다.\n",
    "* 그 대신에 층의 출력을 드롭아웃 비율에 비례하여 줄여 준다.\n",
    "---\n",
    "* 크기가 (batch_size, features)인 한 층의 출력을 담고 있는 넘파이 행렬을 생각해 본다.\n",
    "* 훈련할 때는 이 행렬 값의 일부가 랜덤하게 0이 된다.\n",
    "* `layer_output *= np.random.randint(0, high=2, size=layer_output.shape)`\n",
    "* 테스트할 때는 드롭아웃 비율로 출력을 낮추어 주어야 한다.\n",
    "* 여기에서는 0.5배만큼 스케일을 조정했다.(앞에서 절반의 유닛을 드롭아웃했으므로.)\n",
    "* `layer_output *= 0.5`\n",
    "* 훈련 단계에 이 두 연산을 포함시켜 테스트 단계에는 출력을 그대로 두도록 구현할 수 있다.\n",
    "* `layer_output *= np.random.randint(0, high=2, size=layer_output.shape)`\n",
    "* `layer_output /= 0.5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 핵심 아이디어는 층의 출력 값에 니이즈를 추가하여 중요하지 않은 우연한 패턴을 깨뜨리는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 신경망에서 과대적합을 방지하기 위해 가장 널리 사용하는 방법\n",
    "    * 훈련 데이터를 더 모은다.\n",
    "    * 네트워크의 용량을 감소시킨다.\n",
    "    * 가중치 규제를 추가한다.\n",
    "    * 드롭아웃을 추가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 보편적인 머신 러닝 작업 흐름\n",
    "### 문제 정의와 데이터셋 수집\n",
    "* 먼저 주어진 문제를 정의해야 한다.\n",
    "    * 입력 데이터는 무엇인가? 어떤 것을 예측하려고 하는가? 가용한 훈련 데이터가 있어야 어떤 것을 예측하도록 학습할 수 있다.\n",
    "    * 당면한 문제가 어떤 종류인가? 문제의 유형을 식별하면 모델의 구조와 손실 함수 등을 선택하는 데 도움이 된다.\n",
    "* 입력과 출력이 무엇인지와 어떤 데이터를 사용할 것인지 알기 전까지는 다음 단계로 넘어갈 수 없다.\n",
    "    * 주어진 입력으로 출력을 예측할 수 있다고 가설을 세운다.\n",
    "    * 가용한 데이터에 입력과 출력 사이의 관계를 학습하는 데 충분한 정보가 있다고 가설을 세운다.\n",
    "---\n",
    "* 모델이 작동하기 전까지 이는 가설에 불과하다.\n",
    "* 검증될지 아닐지 기다려 보아야 한다.\n",
    "---\n",
    "* 풀기 어려운 종류의 문제는 시간에 따라 변하는 문제(nonstationary problem)이다.\n",
    "* 최근의 데이터로 주기적으로 모델을 다시 훈련하거나 시간 분포에 맞게 데이터를 수집하여 시간에 따라 변하지 않는 문제로 바꾼다.\n",
    "---\n",
    "* 머신 러닝은 훈련 데이터에 있는 패턴을 기억하기 위해서만 사용한다는 것을 유념해야 한다.\n",
    "* 이미 보았던 것만 인식할 수 있다.\n",
    "* 미래를 예측하기 위해 과거 데이터에서 훈련한 머신 러닝을 사용하는 것은 미래가 과거처럼 움직인다고 가정한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성공 지표 선택\n",
    "* 어떤 것을 제어하려면 관측할 수 있어야 한다.\n",
    "* 성공의 지표가 모델이 최적화할 손실 함수를 선택하는 기준이 된다.\n",
    "---\n",
    "* 클래스 분포가 균일한 분류 문제에서는 정확도와 ROC AUC가 일반적인 지표이다.\n",
    "* 클래수 분포가 균일하지 않은 문제에서는 정밀도와 재현율을 사용할 수 있다.\n",
    "* 랭킹 문제나 다중 레이블 문제에는 **평균 정밀도**를 사용할 수 있다.\n",
    "* 성공을 측정하기 위해 자신만의 지표를 정의하는 일은 일반적이지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가 방법 선택\n",
    "* 목표를 정했다면 현채의 진척 상황을 텽가할 방법을 정해야 한다.\n",
    "    * 홀드아웃 검증 세트 분리: 데이터가 풍부할 때 사용한다.\n",
    "    * K-겹 교차 검증: 홀드아웃 검증을 사용하기에 샘플의 수가 너무 적을 때 사용한다.\n",
    "    * 반복 K-겹 교차 검증: 데이터가 적고 매우 정확한 모델 평가가 필요할 때 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비\n",
    "* 머신 러닝 모델에 주입할 데이터를 구성해야 한다.\n",
    "* 여기에서는 이 머신 러닝 모델을 심층 신경망이라고 가정한다.\n",
    "    * 데이터는 텐서로 구성된다.\n",
    "    * 이 텐서에 있는 값은 일반적으로 작은 값으로 스케일 조정되어 있다.\n",
    "    * 특성마다 범위가 다르면 (여러 종류의 값으로 이루어진 데이터라면) 정규화해야 한다.\n",
    "    * 특성 공학을 수행할 수 있다. 특히 데이터가 적을 때이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본보다 나은 모델 훈련하기\n",
    "* 이 단계의 목표는 **통계적 검정력**(statistical power)을 달성하는 것이다.\n",
    "* 아주 단순한 모델보다 나은 수준의 작은 모델을 개발한다.\n",
    "* MNIST 숫자 이미지 분류 예에서는 0.1보다 높은 정확도를 내는 모델이 통계적 검정력을 가졌다고 말할 수 있다.\n",
    "---\n",
    "* 통계적 검졍력을 달성하는 것이 항상 가능하지는 않다.\n",
    "* 여러 개의 타당성 있는 네트워크 구조를 시도해 보고 무작위로 예측하는 모델보다 낫지 않다면 입력 데이터에 존재하지 않는 것을 얻으려고 한다는 신호일 것이다.\n",
    "    * 주어진 입력으로 출력을 예측할 수 있다고 가설을 세운다.\n",
    "    * 가용한 데이터에 입력과 출력 사이의 관계를 학습하는 데 충분한 정보가 있다고 가설을 세운다.\n",
    "* 이 가설이 잘못된 것일 수 있다. 이때는 기획부터 다시 해야 한다.\n",
    "* 일이 잘 진행된다고 가정하면 첫 번째 모델을 만들기 위해 세 가지 중요한 선택을 해야 한다.\n",
    "    * **마지막 층의 활성화 함수**: 네트워크의 출력에 필요한 제한을 가한다.\n",
    "    * **손실 함수**: 풀려고 하는 문제의 종료에 적합해야 한다.\n",
    "    * **최적화 설정**: 어떤 옵티마이저를 사용하나요? 학습률은 얼마인가요? 대부분의 경우 rmsprop과 기본 학습률을 사용하는 것이 무난하다.\n",
    "---\n",
    "* 손실 함수의 선택에 대해서 언급할 것은 주어진 문제의 성공 지표를 직접 최적화하는 것이 항상 가능하지 않다는 점이다.\n",
    "* 손실 함수는 주어진 미니 배치 데이터에서 계산 가능해야 하고(이상적으로는 손실 함수는 하나의 데이터 포인트에서도 계산 가능해야 한다.)\n",
    "* 미분 가능해야 한다. (그렇지 않으면 역전파 알고리즘을 사용하여 네트워크를 훈련시킬 수 없다.)\n",
    "---\n",
    "|문제 유형|마지막 층의 활성화 함수|손실 함수|\n",
    "|---|---|---|\n",
    "|이진 분류|시그모이드|binary_crossentropy|\n",
    "|단일 레이블 다중 분류|소프트맥스|categorical_crossentropy|\n",
    "|다중 레이블 다중 분류|시그모이드|binary_crossentropy|\n",
    "|임의 값에 대한 회귀|없음|mse|\n",
    "|0과 1 사이 값에 대한 회귀|시그모이드|mse 또는 binary_crossentropy|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 몸집 키우기: 과대적합 모델 구축\n",
    "* 통계적 검정력을 가진 모델을 얻었다면 이제 모델이 충분히 성능을 내는지 질문해 보아야 한다.\n",
    "* 과소적합과 과대적합 사이, 즉 과소용량과 과대용량의 경계에 적절히 위치한 모델이 이상적이다.\n",
    "* 얼마나 큰 모델을 만들어야 하는지 알기 위해서는 과대적합된 모델을 만들어야 한다.\n",
    "    * 층을 추가한다.\n",
    "    * 층의 크기를 키운다.\n",
    "    * 더 많은 에포크 동안 훈련한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 규제와 하이퍼파라미터 튜닝\n",
    "* 이 단계가 대부분의 시간을 차지한다.\n",
    "* 반복적으로 모델을 수정하고 훈련하고 검증 데이터에서 평가한다.(이때 테스트 데이터를 사용하지 않는다.)\n",
    "* 그리고 다시 수정하고 가능한 좋은 모델을 얻을 때까지 반복한다.\n",
    "    * 드롭아웃을 추가한다.\n",
    "    * 층을 추가하거나 제거해서 다른 구조를 시도해 본다.\n",
    "    * L1이나 L2 또는 두 가지 모두 추가한다.\n",
    "    * 최적의 설정을 찾기 위해 하이퍼파라미터를 바꾸어 시도해 본다.(층의 유닛 수나 옵티마이저의 학습률 등.)\n",
    "    * 선택적으로 특성 공학을 시도해 본다. 새로운 탁성을 추가하거나 유용하지 않을 것 같은 특성을 제거한다.\n",
    "---\n",
    "* 검증 과정에서 얻은 피드백을 사용하여 모델을 튜닝할 때마다 검증 과정에 대한 정보를 모델에 누설하고 있다는 것이다.\n",
    "* 몇 번만 반복하는 것은 큰 문제가 되지 않는다.\n",
    "* 하지만 많이 반복하게 되면 결국 모델이 검증 과정에 과대적합될 것이다.(모델이 검증 데이터에서 전혀 훈련되지 않는데도 말이다.)\n",
    "* 이는 검증 과정의 신뢰도를 감소시킨다.\n",
    "---\n",
    "* 만족할 만한 모델 설정을 얻었다면 가용한 모든 데이터(훈련 데이터와 검증 데이터)를 사용해서 제품에 투입할 최종 모델을 훈련시킨다.\n",
    "* 그리고 마지막에 딱 한 번 테스트 세트에서 평가한다.\n",
    "* 테스트 세트의 성능이 검증 데이터에서 측정한 것보다 많이 나쁘다면, 검증 과정에 전혀 신뢰성이 없거나 모델의 하이퍼파라미터를 튜닝하는 동안 검증 데이터에 과대적합된 것이다.\n",
    "* 이련 경우에는 좀 더 신뢰할 만한 평가 방법으로 바꾸는 것이 좋다.(반복 K-겹 교차 검증)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf20')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6031b87587c83867ea9d6a230f58cff6e73fb05ff5d2fb7f6404d0bbff37737a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
