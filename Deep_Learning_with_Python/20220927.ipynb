{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝을 위한 고급 도구"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential 모델을 넘어서: 케라스의 함수형 API\n",
    "* Sequential 모델은 네트워크 입력과 출력이 하나라고 가정한다.\n",
    "* 최근에 개발된 많은 신경망 구조는 선형적이지 않은 네크워크 토폴로지(topology)가 필요하다.\n",
    "* 예를 들어 (구글의 세게디 등이 개발한) **인셉션** 모듈을 사용하는 인셉션 계열의 네트워크들이다.\n",
    "* 모델에 **잔차 연결**을 추가하는 경향도 있다.\n",
    "* 케라스에는 훨씬 더 일반적이고 유연한 다른 방법인 **함수형 API**가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수형 API 소개\n",
    "* **함수형 API**(functional API)에서는 직접 텐서들의 입출력을 다룬다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, layers\n",
    "\n",
    "input_tensor = Input(shape=(32,))\n",
    "dense = layers.Dense(32, activation='relu')\n",
    "\n",
    "output_tensor = dense(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 64)]              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(input_tensor, output_tensor)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 2s 3ms/step - loss: 12.7100\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13.2682\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.6229\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.4729\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18.8948\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.6221\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24.7408\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27.9899\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.6988\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35.6229\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 37.8111\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
    "\n",
    "score = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.81106948852539"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중 입력 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
    "\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 3s 27ms/step - loss: 6.2147 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 6.1970 - acc: 0.0450\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 6.1442 - acc: 0.0090\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.0507 - acc: 0.0050\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.9817 - acc: 0.0080\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.8877 - acc: 0.0110\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.7931 - acc: 0.0180\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.7062 - acc: 0.0300\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.6054 - acc: 0.0440\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.5299 - acc: 0.0470\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 1s 12ms/step - loss: 5.4559 - acc: 0.0620\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.3776 - acc: 0.0790\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.2846 - acc: 0.0950\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.2346 - acc: 0.1050\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.1637 - acc: 0.1090\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.0990 - acc: 0.1160\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.0181 - acc: 0.1220\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.9668 - acc: 0.1430\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.9078 - acc: 0.1300\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.8324 - acc: 0.1500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x220877a99a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
    "\n",
    "answers = np.random.randint(0, answer_vocabulary_size, size=num_samples)\n",
    "\n",
    "answers = to_categorical(answers)\n",
    "\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)\n",
    "\n",
    "model.fit({'text': text, 'question': question}, answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중 출력 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " posts (InputLayer)             [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, None, 256)    12800000    ['posts[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, None, 128)    163968      ['embedding_4[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, None, 128)   0           ['conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, None, 256)    164096      ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, None, 256)    327936      ['conv1d_10[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, None, 256)   0           ['conv1d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, None, 256)    327936      ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, None, 256)    327936      ['conv1d_12[0][0]']              \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Global  (None, 256)         0           ['conv1d_13[0][0]']              \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 128)          32896       ['global_max_pooling1d_1[0][0]'] \n",
      "                                                                                                  \n",
      " age (Dense)                    (None, 1)            129         ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " income (Dense)                 (None, 10)           1290        ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " gender (Dense)                 (None, 1)            129         ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,146,316\n",
      "Trainable params: 14,146,316\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(vocabulary_size, 256)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(\n",
    "    num_income_groups, activation='softmax', name='income'\n",
    ")(x)\n",
    "gender_prediction = layers.Dense(\n",
    "    1, activation='sigmoid', name='gender'\n",
    ")(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이런 모델을 훈련하려면 네트워크 출력마다 다른 손실 함수를 지정해야 한다.\n",
    "* 경사하강법은 하나의 사칼라 값을 최소화하기 때문에 모델을 훈련하려면 이 손실들을 하나의 값으로 합쳐야 한다.\n",
    "* 손실 값을 합치는 가장 간단한 방법은 모두 더하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss=['mse', 'categorical_crossentropy', 'binary_crossentropy']\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss={\n",
    "        'age': 'mse',\n",
    "        'income': 'categorical_crossentropy',\n",
    "        'gender': 'binary_crossentropy'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 손실 값이 많이 불균형하면 모델이 개별 손실이 가장 큰 작업에 치우쳐 표현을 최적화할 것이다.\n",
    "* 그 결과 다른 작업들이 손해를 입는다.\n",
    "* 손실 값이 최종 손실에 기여하는 수춘을 지정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "    loss_weights=[0.25, 1., 10.]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss={\n",
    "        'age': 'mse',\n",
    "        'income': 'categorical_crossentropy',\n",
    "        'gender': 'binary_crossentropy'\n",
    "    },\n",
    "    loss_weights={\n",
    "        'age': 0.25,\n",
    "        'income': 1.,\n",
    "        'gender': 10.\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 4s 18ms/step - loss: 187.2975 - age_loss: 698.5448 - income_loss: 2.5952 - gender_loss: 1.0066\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 146.0611 - age_loss: 541.4639 - income_loss: 2.3597 - gender_loss: 0.8335\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 92.8698 - age_loss: 329.9888 - income_loss: 2.3602 - gender_loss: 0.8012\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 58.1145 - age_loss: 191.7771 - income_loss: 2.3639 - gender_loss: 0.7806\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 50.2089 - age_loss: 161.4221 - income_loss: 2.3652 - gender_loss: 0.7488\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 42.3925 - age_loss: 129.3093 - income_loss: 2.3585 - gender_loss: 0.7707\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 38.1918 - age_loss: 112.6464 - income_loss: 2.3628 - gender_loss: 0.7667\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 35.0435 - age_loss: 100.5818 - income_loss: 2.3622 - gender_loss: 0.7536\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 32.0244 - age_loss: 88.7289 - income_loss: 2.3535 - gender_loss: 0.7489\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 29.2288 - age_loss: 77.7692 - income_loss: 2.3545 - gender_loss: 0.7432\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 28.1592 - age_loss: 73.6066 - income_loss: 2.3552 - gender_loss: 0.7402\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 26.4750 - age_loss: 67.4465 - income_loss: 2.3535 - gender_loss: 0.7260\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 25.0995 - age_loss: 61.8346 - income_loss: 2.3564 - gender_loss: 0.7284\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 23.6302 - age_loss: 56.2404 - income_loss: 2.3530 - gender_loss: 0.7217\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 23.0564 - age_loss: 53.6888 - income_loss: 2.3505 - gender_loss: 0.7284\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 22.2866 - age_loss: 50.9334 - income_loss: 2.3528 - gender_loss: 0.7200\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 20.7226 - age_loss: 44.8723 - income_loss: 2.3522 - gender_loss: 0.7152\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 20.9388 - age_loss: 45.7953 - income_loss: 2.3503 - gender_loss: 0.7140\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 19.8600 - age_loss: 42.1180 - income_loss: 2.3536 - gender_loss: 0.6977\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 18.8246 - age_loss: 39.4251 - income_loss: 2.3475 - gender_loss: 0.6621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x220eea9f820>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "num_samples = 10000\n",
    "max_length = 1000\n",
    "\n",
    "posts = np.random.randint(1, vocabulary_size, size=(num_samples, max_length))\n",
    "\n",
    "age_targets = np.random.randint(0, 80, size=num_samples)\n",
    "income_targets = np.random.randint(0, num_income_groups, size=num_samples)\n",
    "gender_targets = np.random.randint(0, 2, size=num_samples)\n",
    "\n",
    "income_targets = to_categorical(income_targets)\n",
    "\n",
    "model.fit(posts, [age_targets, income_targets, gender_targets], epochs=10, batch_size=64)\n",
    "\n",
    "model.fit(\n",
    "    posts,\n",
    "    {\n",
    "        'age': age_targets,\n",
    "        'income': income_targets,\n",
    "        'gender': gender_targets\n",
    "    },\n",
    "    epochs=10,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 층으로 구성된 비순환 유향 그래프\n",
    "* 함수형 API를 사용하면 다중 입력이나 다중 출력 모델뿐만 아니라 내부 토폴로지가 복잡한 네트워크도 만들 수 있다.\n",
    "* 케라스의 신경망은 층으로 구성된 어떤 **비순환 유향 그래프**(directed acyclic graph)도 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인셉션 모듈\n",
    "* **인셉션**(Inception)은 합성곱 신경망에서 인기 있는 네크워크 구조이다.\n",
    "* **네트워크 안의 네트워크**(network-in-network) 구조에서 영감을 받아 2013~2014년에 크리스티안 세게디(Cristian Szegedy)와 그의 구글 동료들이 만들었다.\n",
    "* 가장 기본적인 인셉션 모듈 형태는 3~4개의 가지를 가진다.\n",
    "* 1x1 합성곱으로 시작해서 3x3 합성곱이 뒤따르고 마지막에 전체 출력 특성이 합쳐진다.\n",
    "* 입력 x는 4D 텐서라고 가정.\n",
    "```\n",
    "from keras import layers\n",
    "branch_a = layers.Conv2D(128, 1, activation='relu', strides=2)(x)\n",
    "\n",
    "branch_b = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)\n",
    "\n",
    "branch_c = layers.AveragePooling2D(3, strides=2)(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu')(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_d = layers.conv2D(128, 3, activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_d)\n",
    "output = layers.concatenate(\n",
    "    [branch_a, branch_b, branch_c, branch_d], axis=-1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 잔차 연결\n",
    "* **잔차 연결**(residual connection)은 엑셉션을 포함하여 2015년 이후 등장한 네트워크 구조에 있는 그래프 형태의 네트워크 컴포넌트이다.\n",
    "* 대규모 딥러닝 모델에서 흔히 나타나는 두 가지 문제인 그래디언트 소실과 표현 평목(representational bottleneck)을 해결했다.\n",
    "* 일반적으로 10개 층 이상을 가진 모델에 잔차 연결을 추가하면 도움이 된다.\n",
    "* 하의 층의 출력이 상위 층의 하캬성화 출력에 연결되는 것이 아니고 더해진다.\n",
    "* 따라서 두 출력의 크기가 동일해야 한다.\n",
    "* 입력 x가 4D 텐서라고 가정.\n",
    "```\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "\n",
    "y = layers.add([y, x])\n",
    "```\n",
    "---\n",
    "```\n",
    "from keras import layers\n",
    "\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y =layers.AmxPooling2D(2, strides=2)(y)\n",
    "\n",
    "residual = layers.Conv2D(128, 1, strides=2, padding='same')(x)\n",
    "\n",
    "y = layers.add([y, residual])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 층 가중치 공유\n",
    "* 함수형 API의 중요한 또 하나의 기능은 층 객체를 여러 번 재사용할 수 있다는 것이다.\n",
    "* 층 객체를 두 번 호출하면 새로운 층 객체를 만들지 않고 각 호출에 동일한 가중치를 재사용한다.\n",
    "* 하나의 LSTM 층으로 양쭉을 모두 처리하는 것\n",
    "* 이 LSTM 층의 표현(가중치)은 두 입력에 대해 함께 학습.\n",
    "* **샴 LSTM**(Siames LSTM) 모델 또는 **공유 LSTM**.\n",
    "```\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "lstm = layers.LSTM(32)\n",
    "left_input = Input(shape=(None, 128))\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "right_input = Input(shape=(None, 128))\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model([left_input, right_input], predictions)\n",
    "model.fit([left_data, right_data], targets)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 층과 모델\n",
    "* 함수형 API에서는 모델을 층처럼 사용할 수 있다.\n",
    "```\n",
    "from keras import layers\n",
    "from keras import applications\n",
    "from keras import Input\n",
    "\n",
    "xception_base = applications.Xception(weights=None, include_top=False)\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "\n",
    "left_features = xception_base(left_input)\n",
    "right_features = xception_base(right_input)\n",
    "\n",
    "merged_features = layers.concatenate(\n",
    "    [left_features, right_features], axis=-1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정리\n",
    "* 차례대로 층을 쌓는 것 이상이 빌요할 때는 Sequential API를 사용하지 않는다.\n",
    "* 함수형 API를 사용하여 다중 입력, 다중 출력, 복잡한 네트워크 토폴라지를 갖는 케라스 모델을 만드는 방법\n",
    "* 다른 네트워크 가지에서 같은 층이나 모델 객체를 여러 번 호출하여 가중치를 재사용하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf20')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6031b87587c83867ea9d6a230f58cff6e73fb05ff5d2fb7f6404d0bbff37737a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
